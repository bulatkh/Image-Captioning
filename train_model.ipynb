{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from configs.default import _C as config\n",
    "from configs.default import update_config\n",
    "\n",
    "from datasets import flickr8k_parse\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from models import batch_generator, decoder\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import path_generation\n",
    "import tensorflow as tf\n",
    "import text_processing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 12006001025085623202, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 1462032793\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 6801201856544217791\n",
       " physical_device_desc: \"device: 0, name: GeForce 840M, pci bus id: 0000:07:00.0, compute capability: 5.0\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./configs/attn.yaml\"\n",
    "update_config(config, config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captions encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building decoder, it is necessary to encode captions into one-hot vectors which further would be used in embedding layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.DATASET == 'Coco':\n",
    "    if config.ATTENTION:\n",
    "        features_file_train = \"vgg16_coco_train_attn.npy\"\n",
    "        features_file_val = \"vgg16_coco_val_attn.npy\"\n",
    "    else:\n",
    "        features_file_train = \"vgg16_coco_train.npy\"\n",
    "        features_file_val = \"vgg16_coco_val.npy\"\n",
    "    \n",
    "    \n",
    "    val_filenames_with_captions = coco_parse.get_image_filename_with_caption(config.PATH.ANNOTATIONS_PATH, \n",
    "                                                                             config.PATH.IMG_PATH, \n",
    "                                                                             train=False)\n",
    "\n",
    "    val_filenames_with_all_captions = coco_parse.get_image_with_all_captions(val_filenames_with_captions)\n",
    "\n",
    "    train_filenames_with_captions = coco_parse.get_image_filename_with_caption(config.PATH.ANNOTATIONS_PATH, \n",
    "                                                                               config.PATH.IMG_PATH,\n",
    "                                                                               train=True)\n",
    "    train_filenames_with_all_captions = coco_parse.get_image_with_all_captions(train_filenames_with_captions)\n",
    "\n",
    "    ### Extract captions\n",
    "    train_captions = coco_parse.make_list_of_captions(train_filenames_with_all_captions)\n",
    "    val_captions = coco_parse.make_list_of_captions(val_filenames_with_all_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flickr8k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.DATASET == 'Flickr8k':\n",
    "    if config.ATTENTION:\n",
    "        features_file_train = \"vgg16_flickr8k_train_attn.npy\"\n",
    "        features_file_val = \"vgg16_flickr8k_val_attn.npy\"\n",
    "    else:\n",
    "        features_file_train = \"vgg16_flickr8k_train.npy\"\n",
    "        features_file_val = \"vgg16_flickr8k_val.npy\"\n",
    "\n",
    "    captions_file = os.path.join(config.PATH.ANNOTATIONS_PATH, \"Flickr8k.token.txt\")\n",
    "    train_txt_path = os.path.join(config.PATH.ANNOTATIONS_PATH, \"Flickr_8k.trainImages.txt\")\n",
    "    dev_txt_path = os.path.join(config.PATH.ANNOTATIONS_PATH, \"Flickr_8k.devImages.txt\")\n",
    "    test_txt_path = os.path.join(config.PATH.ANNOTATIONS_PATH, \"Flickr_8k.testImages.txt\")    \n",
    "        \n",
    "    filenames_with_all_captions = flickr8k_parse.generate_filenames_with_all_captions(captions_file, \n",
    "                                                                                      config.PATH.IMG_PATH)\n",
    "    train_filenames_with_all_captions = flickr8k_parse.generate_set(train_txt_path, \n",
    "                                                                    filenames_with_all_captions,\n",
    "                                                                    config.PATH.IMG_PATH)\n",
    "    val_filenames_with_all_captions = flickr8k_parse.generate_set(dev_txt_path, \n",
    "                                                                  filenames_with_all_captions, \n",
    "                                                                  config.PATH.IMG_PATH)\n",
    "    test_filenames_with_all_captions = flickr8k_parse.generate_set(test_txt_path, \n",
    "                                                                   filenames_with_all_captions, \n",
    "                                                                   config.PATH.IMG_PATH)\n",
    "\n",
    "    train_captions = flickr8k_parse.make_list_of_captions(train_filenames_with_all_captions)\n",
    "    val_captions = flickr8k_parse.make_list_of_captions(val_filenames_with_all_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess captions\n",
    "text_processing.preprocess_captions(val_captions)\n",
    "text_processing.preprocess_captions(train_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add markers of captions' starts and ends\n",
    "text_processing.add_start_and_end_to_captions(train_captions)\n",
    "text_processing.add_start_and_end_to_captions(val_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create vocabulary from the training captions\n",
    "train_vocab = text_processing.Vocabulary()\n",
    "for caption_list in train_captions:\n",
    "    for caption in caption_list:\n",
    "        tmp_caption_list = caption.split()\n",
    "        for word in tmp_caption_list:\n",
    "            train_vocab.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(config.PATH.VOCABULARY_PATH):\n",
    "    os.mkdir(config.PATH.VOCABULARY_PATH)\n",
    "train_vocab.save_vocabulary(config.VOCABULARY.WORD_TO_ID, config.VOCABULARY.ID_TO_WORD, config.VOCABULARY.COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_captions_tokens = text_processing.tokenise_captions(train_captions, train_vocab)\n",
    "val_captions_tokens = text_processing.tokenise_captions(val_captions, train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 6, 7, 2, 8, 4, 9, 10, 11, 12],\n",
       " [1, 3, 4, 13, 14, 4, 15, 11, 12],\n",
       " [1, 16, 17, 18, 19, 20, 21, 10, 22, 23, 12],\n",
       " [1, 16, 17, 24, 25, 9, 10, 11, 12],\n",
       " [1, 16, 17, 6, 15, 2, 26, 27, 28, 29, 30, 12]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_captions_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> a black dog is running after a white dog in the snow <eos>',\n",
       " '<sos> black dog chasing brown dog through snow <eos>',\n",
       " '<sos> two dogs chase each other across the snowy ground <eos>',\n",
       " '<sos> two dogs play together in the snow <eos>',\n",
       " '<sos> two dogs running through a low lying body of water <eos>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_captions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gen = path_generation.PathGenerator(config.DECODER.GRU, \n",
    "                                         config.DATASET, \n",
    "                                         config.DECODER.NUM_RNN_LAYERS, \n",
    "                                         config.DECODER.BATCH_SIZE, \n",
    "                                         config.DECODER.BATCH_NORM, \n",
    "                                         config.DECODER.DROPOUT, \n",
    "                                         config.ATTENTION, \n",
    "                                         config.DECODER.ATTN_TYPE)\n",
    "\n",
    "path_checkpoint = path_gen.get_weights_path()\n",
    "model_path = path_gen.get_model_path()\n",
    "callbacks_path = path_gen.get_callbacks_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file_train_path = os.path.join(config.PATH.FEATURES_PATH, features_file_train)\n",
    "features_file_val_path = os.path.join(config.PATH.FEATURES_PATH, features_file_val)\n",
    "\n",
    "transfer_values = np.load(features_file_train_path)\n",
    "val_transfer_values = np.load(features_file_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 14, 14, 512)\n",
      "(6000, 196, 512)\n"
     ]
    }
   ],
   "source": [
    "if config.ATTENTION:\n",
    "    print(transfer_values.shape)\n",
    "    transfer_values = transfer_values.reshape(len(train_filenames_with_all_captions), transfer_values.shape[1] ** 2, -1)\n",
    "    val_transfer_values = val_transfer_values.reshape(len(val_filenames_with_all_captions), val_transfer_values.shape[1] ** 2, -1)\n",
    "    print(transfer_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "decoder_model = decoder.Decoder(config.DECODER.INITIAL_STATE_SIZE,\n",
    "                                config.DECODER.EMBEDDING_OUT_SIZE,\n",
    "                                config.DECODER.NUM_RNN_LAYERS,\n",
    "                                config.DECODER.GRU,\n",
    "                                config.DECODER.BATCH_NORM,\n",
    "                                config.DECODER.DROPOUT,\n",
    "                                config.ATTENTION,\n",
    "                                config.DECODER.ATTN_TYPE,\n",
    "                                transfer_values,\n",
    "                                train_vocab)\n",
    "decoder_model = decoder_model.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.DECODER.GRU:\n",
    "    generator = batch_generator.generate_batch(transfer_values, \n",
    "                                               train_captions_tokens, \n",
    "                                               number_of_words=train_vocab.number_of_words, \n",
    "                                               batch_size=config.DECODER.BATCH_SIZE)\n",
    "    val_generator = batch_generator.generate_batch(val_transfer_values, \n",
    "                                                   val_captions_tokens, \n",
    "                                                   number_of_words=train_vocab.number_of_words, \n",
    "                                                   batch_size=config.DECODER.BATCH_SIZE)\n",
    "else:\n",
    "    generator = batch_generator.generate_batch(transfer_values, \n",
    "                                               train_captions_tokens, \n",
    "                                               number_of_words=train_vocab.number_of_words, \n",
    "                                               batch_size=config.DECODER.BATCH_SIZE, \n",
    "                                               gru=config.DECODER.GRU)\n",
    "    \n",
    "    val_generator = batch_generator.generate_batch(val_transfer_values, \n",
    "                                                   val_captions_tokens, \n",
    "                                                   number_of_words=train_vocab.number_of_words, \n",
    "                                                   batch_size=config.DECODER.BATCH_SIZE, \n",
    "                                                   gru=config.DECODER.GRU)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if config.DECODER.OPTIMIZER:\n",
    "    optimizer = RMSprop(lr=config.DECODER.LR, decay=config.DECODER.DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model.compile(optimizer=optimizer,\n",
    "                      loss=config.DECODER.LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'batch_normalization_5/cond/Merge:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'batch_normalization_6/cond/Merge:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_1/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_1/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_2/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_2/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_3/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_3/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_4/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_4/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_5/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_5/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_6/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_6/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_7/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_7/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_8/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_8/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_9/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_9/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_10/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_10/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_11/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_11/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_12/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_12/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_13/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_13/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_14/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_14/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_15/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_15/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_16/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_16/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_17/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_17/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_18/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_18/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_19/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_19/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_20/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_20/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_21/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_21/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_22/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_22/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_23/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_23/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_24/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_24/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_25/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_25/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_26/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_26/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_27/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_27/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1_28/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1_28/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'batch_normalization_5/cond/Merge:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'batch_normalization_6/cond/Merge:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder already exists\n"
     ]
    }
   ],
   "source": [
    "model_json = decoder_model.to_json()\n",
    "try:\n",
    "    os.mkdir(config.PATH.MODELS_ARCHITECTURE_PATH)\n",
    "except:\n",
    "    print('The folder already exists')\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json.dump(json.loads(model_json), json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints\n",
    "\n",
    "During the training process, it is a good idea to save the weights periodically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(configs.WEIGHTS_PATH)\n",
    "except:\n",
    "    print('The folder already exists')\n",
    "\n",
    "checkpoints = ModelCheckpoint(path_checkpoint, \n",
    "                              verbose=config.DECODER.VERBOSE, \n",
    "                              save_weights_only=True, \n",
    "                              save_best_only=config.DECODER.SAVE_BEST)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=config.DECODER.MONITOR, \n",
    "                              factor=config.DECODER.FACTOR,\n",
    "                              patience=config.DECODER.PATIENCE, \n",
    "                              verbose=config.DECODER.VERBOSE, \n",
    "                              min_lr=config.DECODER.MIN_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/20\n",
      "187/187 [==============================] - ETA: 2:35:08 - loss: 8.98 - ETA: 1:19:35 - loss: 8.09 - ETA: 54:22 - loss: 7.2711 - ETA: 41:44 - loss: 6.67 - ETA: 34:09 - loss: 6.21 - ETA: 29:05 - loss: 5.92 - ETA: 25:27 - loss: 5.62 - ETA: 22:44 - loss: 5.35 - ETA: 20:36 - loss: 5.09 - ETA: 18:54 - loss: 4.90 - ETA: 17:29 - loss: 4.72 - ETA: 16:19 - loss: 4.53 - ETA: 15:19 - loss: 4.37 - ETA: 14:28 - loss: 4.22 - ETA: 13:43 - loss: 4.08 - ETA: 13:04 - loss: 3.97 - ETA: 12:29 - loss: 3.86 - ETA: 11:58 - loss: 3.77 - ETA: 11:30 - loss: 3.69 - ETA: 11:04 - loss: 3.61 - ETA: 10:41 - loss: 3.54 - ETA: 10:20 - loss: 3.48 - ETA: 10:00 - loss: 3.42 - ETA: 9:42 - loss: 3.3669 - ETA: 9:26 - loss: 3.328 - ETA: 9:10 - loss: 3.281 - ETA: 8:56 - loss: 3.240 - ETA: 8:42 - loss: 3.202 - ETA: 8:29 - loss: 3.165 - ETA: 8:17 - loss: 3.133 - ETA: 8:06 - loss: 3.104 - ETA: 7:55 - loss: 3.070 - ETA: 7:45 - loss: 3.043 - ETA: 7:36 - loss: 3.017 - ETA: 7:26 - loss: 2.989 - ETA: 7:18 - loss: 2.968 - ETA: 7:09 - loss: 2.942 - ETA: 7:01 - loss: 2.918 - ETA: 6:54 - loss: 2.894 - ETA: 6:46 - loss: 2.867 - ETA: 6:39 - loss: 2.844 - ETA: 6:32 - loss: 2.820 - ETA: 6:26 - loss: 2.805 - ETA: 6:19 - loss: 2.784 - ETA: 6:13 - loss: 2.769 - ETA: 6:07 - loss: 2.747 - ETA: 6:01 - loss: 2.729 - ETA: 5:56 - loss: 2.710 - ETA: 5:50 - loss: 2.695 - ETA: 5:45 - loss: 2.684 - ETA: 5:40 - loss: 2.668 - ETA: 5:35 - loss: 2.653 - ETA: 5:30 - loss: 2.633 - ETA: 5:26 - loss: 2.622 - ETA: 5:21 - loss: 2.607 - ETA: 5:17 - loss: 2.591 - ETA: 5:12 - loss: 2.574 - ETA: 5:08 - loss: 2.557 - ETA: 5:04 - loss: 2.542 - ETA: 5:00 - loss: 2.535 - ETA: 4:55 - loss: 2.521 - ETA: 4:52 - loss: 2.510 - ETA: 4:48 - loss: 2.497 - ETA: 4:44 - loss: 2.484 - ETA: 4:40 - loss: 2.475 - ETA: 4:36 - loss: 2.464 - ETA: 4:33 - loss: 2.452 - ETA: 4:29 - loss: 2.441 - ETA: 4:26 - loss: 2.433 - ETA: 4:22 - loss: 2.425 - ETA: 4:19 - loss: 2.415 - ETA: 4:16 - loss: 2.405 - ETA: 4:12 - loss: 2.395 - ETA: 4:09 - loss: 2.388 - ETA: 4:06 - loss: 2.378 - ETA: 4:03 - loss: 2.371 - ETA: 4:00 - loss: 2.362 - ETA: 3:57 - loss: 2.354 - ETA: 3:54 - loss: 2.348 - ETA: 3:51 - loss: 2.342 - ETA: 3:48 - loss: 2.334 - ETA: 3:45 - loss: 2.330 - ETA: 3:42 - loss: 2.322 - ETA: 3:39 - loss: 2.317 - ETA: 3:36 - loss: 2.312 - ETA: 3:33 - loss: 2.307 - ETA: 3:31 - loss: 2.301 - ETA: 3:28 - loss: 2.296 - ETA: 3:25 - loss: 2.289 - ETA: 3:23 - loss: 2.283 - ETA: 3:20 - loss: 2.276 - ETA: 3:17 - loss: 2.271 - ETA: 3:15 - loss: 2.262 - ETA: 3:12 - loss: 2.256 - ETA: 3:09 - loss: 2.250 - ETA: 3:07 - loss: 2.244 - ETA: 3:04 - loss: 2.238 - ETA: 3:02 - loss: 2.230 - ETA: 2:59 - loss: 2.223 - ETA: 2:57 - loss: 2.218 - ETA: 2:54 - loss: 2.213 - ETA: 2:52 - loss: 2.208 - ETA: 2:50 - loss: 2.201 - ETA: 2:47 - loss: 2.196 - ETA: 2:45 - loss: 2.192 - ETA: 2:42 - loss: 2.187 - ETA: 2:40 - loss: 2.185 - ETA: 2:38 - loss: 2.181 - ETA: 2:35 - loss: 2.177 - ETA: 2:33 - loss: 2.171 - ETA: 2:31 - loss: 2.167 - ETA: 2:29 - loss: 2.161 - ETA: 2:26 - loss: 2.156 - ETA: 2:24 - loss: 2.152 - ETA: 2:22 - loss: 2.147 - ETA: 2:20 - loss: 2.143 - ETA: 2:17 - loss: 2.138 - ETA: 2:15 - loss: 2.136 - ETA: 2:13 - loss: 2.129 - ETA: 2:11 - loss: 2.125 - ETA: 2:09 - loss: 2.121 - ETA: 2:06 - loss: 2.118 - ETA: 2:04 - loss: 2.113 - ETA: 2:02 - loss: 2.108 - ETA: 2:00 - loss: 2.103 - ETA: 1:58 - loss: 2.101 - ETA: 1:56 - loss: 2.097 - ETA: 1:54 - loss: 2.092 - ETA: 1:51 - loss: 2.089 - ETA: 1:49 - loss: 2.084 - ETA: 1:47 - loss: 2.080 - ETA: 1:45 - loss: 2.076 - ETA: 1:43 - loss: 2.072 - ETA: 1:41 - loss: 2.067 - ETA: 1:39 - loss: 2.063 - ETA: 1:37 - loss: 2.059 - ETA: 1:35 - loss: 2.056 - ETA: 1:33 - loss: 2.051 - ETA: 1:31 - loss: 2.049 - ETA: 1:29 - loss: 2.044 - ETA: 1:27 - loss: 2.041 - ETA: 1:25 - loss: 2.039 - ETA: 1:23 - loss: 2.037 - ETA: 1:21 - loss: 2.035 - ETA: 1:19 - loss: 2.030 - ETA: 1:17 - loss: 2.027 - ETA: 1:15 - loss: 2.023 - ETA: 1:13 - loss: 2.020 - ETA: 1:11 - loss: 2.015 - ETA: 1:09 - loss: 2.013 - ETA: 1:07 - loss: 2.010 - ETA: 1:05 - loss: 2.009 - ETA: 1:03 - loss: 2.006 - ETA: 1:01 - loss: 2.003 - ETA: 59s - loss: 2.000 - ETA: 57s - loss: 1.99 - ETA: 55s - loss: 1.99 - ETA: 53s - loss: 1.99 - ETA: 52s - loss: 1.98 - ETA: 50s - loss: 1.98 - ETA: 48s - loss: 1.98 - ETA: 46s - loss: 1.98 - ETA: 44s - loss: 1.98 - ETA: 42s - loss: 1.97 - ETA: 40s - loss: 1.97 - ETA: 38s - loss: 1.97 - ETA: 36s - loss: 1.97 - ETA: 35s - loss: 1.96 - ETA: 33s - loss: 1.96 - ETA: 31s - loss: 1.96 - ETA: 29s - loss: 1.96 - ETA: 27s - loss: 1.95 - ETA: 25s - loss: 1.95 - ETA: 23s - loss: 1.95 - ETA: 21s - loss: 1.94 - ETA: 20s - loss: 1.94 - ETA: 18s - loss: 1.94 - ETA: 16s - loss: 1.94 - ETA: 14s - loss: 1.94 - ETA: 12s - loss: 1.94 - ETA: 10s - loss: 1.93 - ETA: 9s - loss: 1.9355 - ETA: 7s - loss: 1.934 - ETA: 5s - loss: 1.930 - ETA: 3s - loss: 1.929 - ETA: 1s - loss: 1.926 - 344s 2s/step - loss: 1.9254 - val_loss: 8.1636\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 8.16355, saving model to ./model_files/weights/VGG16_LSTM_Flickr8k_2l_32b_bn_dr_attn_bahdanau.hdf5\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:48 - loss: 1.444 - ETA: 4:47 - loss: 1.419 - ETA: 4:46 - loss: 1.460 - ETA: 4:44 - loss: 1.482 - ETA: 4:43 - loss: 1.474 - ETA: 4:41 - loss: 1.526 - ETA: 4:39 - loss: 1.503 - ETA: 4:38 - loss: 1.513 - ETA: 4:37 - loss: 1.496 - ETA: 4:35 - loss: 1.492 - ETA: 4:33 - loss: 1.493 - ETA: 4:32 - loss: 1.485 - ETA: 4:30 - loss: 1.479 - ETA: 4:29 - loss: 1.491 - ETA: 4:27 - loss: 1.486 - ETA: 4:26 - loss: 1.492 - ETA: 4:24 - loss: 1.492 - ETA: 4:23 - loss: 1.483 - ETA: 4:21 - loss: 1.483 - ETA: 4:19 - loss: 1.487 - ETA: 4:18 - loss: 1.487 - ETA: 4:16 - loss: 1.478 - ETA: 4:15 - loss: 1.481 - ETA: 4:13 - loss: 1.478 - ETA: 4:12 - loss: 1.473 - ETA: 4:10 - loss: 1.474 - ETA: 4:09 - loss: 1.479 - ETA: 4:07 - loss: 1.480 - ETA: 4:06 - loss: 1.478 - ETA: 4:04 - loss: 1.485 - ETA: 4:02 - loss: 1.484 - ETA: 4:01 - loss: 1.482 - ETA: 3:59 - loss: 1.477 - ETA: 3:58 - loss: 1.476 - ETA: 3:56 - loss: 1.477 - ETA: 3:55 - loss: 1.478 - ETA: 3:53 - loss: 1.473 - ETA: 3:51 - loss: 1.472 - ETA: 3:50 - loss: 1.474 - ETA: 3:48 - loss: 1.471 - ETA: 3:47 - loss: 1.470 - ETA: 3:45 - loss: 1.467 - ETA: 3:44 - loss: 1.468 - ETA: 3:42 - loss: 1.472 - ETA: 3:41 - loss: 1.470 - ETA: 3:39 - loss: 1.472 - ETA: 3:37 - loss: 1.470 - ETA: 3:36 - loss: 1.468 - ETA: 3:34 - loss: 1.474 - ETA: 3:33 - loss: 1.473 - ETA: 3:31 - loss: 1.469 - ETA: 3:30 - loss: 1.472 - ETA: 3:28 - loss: 1.475 - ETA: 3:26 - loss: 1.474 - ETA: 4:37 - loss: 1.474 - ETA: 5:21 - loss: 1.475 - ETA: 5:33 - loss: 1.473 - ETA: 5:31 - loss: 1.475 - ETA: 5:29 - loss: 1.476 - ETA: 5:27 - loss: 1.479 - ETA: 5:25 - loss: 1.479 - ETA: 5:22 - loss: 1.481 - ETA: 5:18 - loss: 1.479 - ETA: 5:14 - loss: 1.476 - ETA: 5:10 - loss: 1.478 - ETA: 5:07 - loss: 1.479 - ETA: 5:03 - loss: 1.478 - ETA: 4:59 - loss: 1.483 - ETA: 4:56 - loss: 1.481 - ETA: 4:52 - loss: 1.480 - ETA: 4:48 - loss: 1.479 - ETA: 4:45 - loss: 1.479 - ETA: 4:41 - loss: 1.481 - ETA: 4:37 - loss: 1.481 - ETA: 4:34 - loss: 1.481 - ETA: 4:30 - loss: 1.482 - ETA: 4:27 - loss: 1.482 - ETA: 4:23 - loss: 1.479 - ETA: 4:20 - loss: 1.476 - ETA: 4:17 - loss: 1.476 - ETA: 4:13 - loss: 1.473 - ETA: 4:10 - loss: 1.472 - ETA: 4:06 - loss: 1.471 - ETA: 4:03 - loss: 1.473 - ETA: 4:00 - loss: 1.473 - ETA: 3:57 - loss: 1.472 - ETA: 3:54 - loss: 1.473 - ETA: 3:50 - loss: 1.471 - ETA: 3:47 - loss: 1.470 - ETA: 3:44 - loss: 1.472 - ETA: 3:41 - loss: 1.472 - ETA: 3:38 - loss: 1.472 - ETA: 3:35 - loss: 1.472 - ETA: 3:32 - loss: 1.472 - ETA: 3:29 - loss: 1.471 - ETA: 3:26 - loss: 1.470 - ETA: 3:24 - loss: 1.471 - ETA: 3:21 - loss: 1.471 - ETA: 3:18 - loss: 1.471 - ETA: 3:15 - loss: 1.471 - ETA: 3:12 - loss: 1.471 - ETA: 3:10 - loss: 1.472 - ETA: 3:07 - loss: 1.471 - ETA: 3:04 - loss: 1.469 - ETA: 3:01 - loss: 1.467 - ETA: 2:59 - loss: 1.466 - ETA: 2:56 - loss: 1.466 - ETA: 2:53 - loss: 1.466 - ETA: 2:51 - loss: 1.464 - ETA: 2:48 - loss: 1.463 - ETA: 2:46 - loss: 1.463 - ETA: 2:43 - loss: 1.463 - ETA: 2:41 - loss: 1.465 - ETA: 2:38 - loss: 1.465 - ETA: 2:35 - loss: 1.464 - ETA: 2:33 - loss: 1.464 - ETA: 2:30 - loss: 1.464 - ETA: 2:28 - loss: 1.462 - ETA: 2:26 - loss: 1.461 - ETA: 2:23 - loss: 1.460 - ETA: 2:21 - loss: 1.459 - ETA: 2:18 - loss: 1.459 - ETA: 2:16 - loss: 1.459 - ETA: 2:13 - loss: 1.459 - ETA: 2:11 - loss: 1.459 - ETA: 2:09 - loss: 1.459 - ETA: 2:06 - loss: 1.458 - ETA: 2:04 - loss: 1.458 - ETA: 2:02 - loss: 1.459 - ETA: 1:59 - loss: 1.459 - ETA: 1:57 - loss: 1.457 - ETA: 1:55 - loss: 1.457 - ETA: 1:52 - loss: 1.455 - ETA: 1:50 - loss: 1.454 - ETA: 1:48 - loss: 1.454 - ETA: 1:46 - loss: 1.455 - ETA: 1:43 - loss: 1.456 - ETA: 1:41 - loss: 1.453 - ETA: 1:39 - loss: 1.452 - ETA: 1:37 - loss: 1.453 - ETA: 1:34 - loss: 1.453 - ETA: 1:32 - loss: 1.452 - ETA: 1:30 - loss: 1.451 - ETA: 1:28 - loss: 1.452 - ETA: 1:26 - loss: 1.451 - ETA: 1:23 - loss: 1.451 - ETA: 1:21 - loss: 1.449 - ETA: 1:19 - loss: 1.449 - ETA: 1:17 - loss: 1.449 - ETA: 1:15 - loss: 1.449 - ETA: 1:13 - loss: 1.448 - ETA: 1:10 - loss: 1.448 - ETA: 1:08 - loss: 1.448 - ETA: 1:06 - loss: 1.448 - ETA: 1:04 - loss: 1.449 - ETA: 1:02 - loss: 1.449 - ETA: 1:00 - loss: 1.448 - ETA: 58s - loss: 1.446 - ETA: 56s - loss: 1.44 - ETA: 54s - loss: 1.44 - ETA: 51s - loss: 1.44 - ETA: 49s - loss: 1.44 - ETA: 47s - loss: 1.44 - ETA: 45s - loss: 1.44 - ETA: 43s - loss: 1.44 - ETA: 41s - loss: 1.44 - ETA: 39s - loss: 1.44 - ETA: 37s - loss: 1.44 - ETA: 35s - loss: 1.44 - ETA: 33s - loss: 1.44 - ETA: 31s - loss: 1.44 - ETA: 29s - loss: 1.44 - ETA: 27s - loss: 1.44 - ETA: 25s - loss: 1.44 - ETA: 23s - loss: 1.44 - ETA: 21s - loss: 1.44 - ETA: 19s - loss: 1.44 - ETA: 17s - loss: 1.44 - ETA: 15s - loss: 1.44 - ETA: 13s - loss: 1.44 - ETA: 11s - loss: 1.44 - ETA: 9s - loss: 1.4409 - ETA: 7s - loss: 1.440 - ETA: 5s - loss: 1.439 - ETA: 3s - loss: 1.439 - ETA: 1s - loss: 1.439 - 364s 2s/step - loss: 1.4391 - val_loss: 5.9795\n",
      "\n",
      "Epoch 00002: val_loss improved from 8.16355 to 5.97949, saving model to ./model_files/weights/VGG16_LSTM_Flickr8k_2l_32b_bn_dr_attn_bahdanau.hdf5\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:48 - loss: 1.493 - ETA: 4:46 - loss: 1.503 - ETA: 4:45 - loss: 1.524 - ETA: 4:44 - loss: 1.518 - ETA: 4:43 - loss: 1.501 - ETA: 4:41 - loss: 1.480 - ETA: 4:40 - loss: 1.474 - ETA: 4:38 - loss: 1.449 - ETA: 4:37 - loss: 1.444 - ETA: 4:35 - loss: 1.440 - ETA: 4:33 - loss: 1.459 - ETA: 4:32 - loss: 1.458 - ETA: 4:30 - loss: 1.462 - ETA: 4:29 - loss: 1.460 - ETA: 4:27 - loss: 1.443 - ETA: 4:26 - loss: 1.436 - ETA: 4:24 - loss: 1.432 - ETA: 4:37 - loss: 1.435 - ETA: 4:47 - loss: 1.432 - ETA: 4:58 - loss: 1.422 - ETA: 5:07 - loss: 1.407 - ETA: 5:19 - loss: 1.412 - ETA: 5:28 - loss: 1.411 - ETA: 5:35 - loss: 1.407 - ETA: 5:40 - loss: 1.404 - ETA: 5:45 - loss: 1.406 - ETA: 5:48 - loss: 1.410 - ETA: 5:51 - loss: 1.410 - ETA: 5:57 - loss: 1.410 - ETA: 6:02 - loss: 1.411 - ETA: 6:05 - loss: 1.411 - ETA: 6:05 - loss: 1.409 - ETA: 6:04 - loss: 1.408 - ETA: 6:04 - loss: 1.408 - ETA: 6:03 - loss: 1.409 - ETA: 6:02 - loss: 1.404 - ETA: 5:58 - loss: 1.399 - ETA: 5:55 - loss: 1.398 - ETA: 5:52 - loss: 1.399 - ETA: 5:49 - loss: 1.403 - ETA: 5:46 - loss: 1.404 - ETA: 5:43 - loss: 1.403 - ETA: 5:40 - loss: 1.401 - ETA: 5:36 - loss: 1.400 - ETA: 5:32 - loss: 1.401 - ETA: 5:28 - loss: 1.401 - ETA: 5:24 - loss: 1.403 - ETA: 5:20 - loss: 1.401 - ETA: 5:17 - loss: 1.404 - ETA: 5:13 - loss: 1.405 - ETA: 5:09 - loss: 1.404 - ETA: 5:06 - loss: 1.402 - ETA: 5:02 - loss: 1.402 - ETA: 4:58 - loss: 1.404 - ETA: 4:55 - loss: 1.403 - ETA: 4:51 - loss: 1.402 - ETA: 4:48 - loss: 1.405 - ETA: 4:45 - loss: 1.407 - ETA: 4:41 - loss: 1.407 - ETA: 4:38 - loss: 1.406 - ETA: 4:35 - loss: 1.405 - ETA: 4:32 - loss: 1.405 - ETA: 4:28 - loss: 1.404 - ETA: 4:25 - loss: 1.402 - ETA: 4:22 - loss: 1.401 - ETA: 4:19 - loss: 1.399 - ETA: 4:16 - loss: 1.398 - ETA: 4:13 - loss: 1.399 - ETA: 4:10 - loss: 1.400 - ETA: 4:07 - loss: 1.401 - ETA: 4:04 - loss: 1.402 - ETA: 4:02 - loss: 1.403 - ETA: 3:59 - loss: 1.400 - ETA: 3:56 - loss: 1.400 - ETA: 3:53 - loss: 1.399 - ETA: 3:51 - loss: 1.397 - ETA: 3:48 - loss: 1.396 - ETA: 3:45 - loss: 1.396 - ETA: 3:43 - loss: 1.397 - ETA: 3:40 - loss: 1.396 - ETA: 3:38 - loss: 1.397 - ETA: 3:35 - loss: 1.395 - ETA: 3:32 - loss: 1.396 - ETA: 3:30 - loss: 1.397 - ETA: 3:27 - loss: 1.397 - ETA: 3:25 - loss: 1.396 - ETA: 3:23 - loss: 1.395 - ETA: 3:20 - loss: 1.396 - ETA: 3:18 - loss: 1.398 - ETA: 3:15 - loss: 1.397 - ETA: 3:13 - loss: 1.396 - ETA: 3:11 - loss: 1.395 - ETA: 3:08 - loss: 1.395 - ETA: 3:06 - loss: 1.398 - ETA: 3:04 - loss: 1.396 - ETA: 3:01 - loss: 1.395 - ETA: 2:59 - loss: 1.396 - ETA: 2:57 - loss: 1.395 - ETA: 2:54 - loss: 1.394 - ETA: 2:52 - loss: 1.394 - ETA: 2:50 - loss: 1.394 - ETA: 2:48 - loss: 1.396 - ETA: 2:45 - loss: 1.395 - ETA: 2:43 - loss: 1.395 - ETA: 2:41 - loss: 1.394 - ETA: 2:39 - loss: 1.393 - ETA: 2:37 - loss: 1.396 - ETA: 2:34 - loss: 1.397 - ETA: 2:32 - loss: 1.397 - ETA: 2:30 - loss: 1.395 - ETA: 2:28 - loss: 1.394 - ETA: 2:26 - loss: 1.395 - ETA: 2:24 - loss: 1.393 - ETA: 2:21 - loss: 1.393 - ETA: 2:19 - loss: 1.393 - ETA: 2:17 - loss: 1.392 - ETA: 2:15 - loss: 1.393 - ETA: 2:13 - loss: 1.393 - ETA: 2:11 - loss: 1.392 - ETA: 2:09 - loss: 1.391 - ETA: 2:07 - loss: 1.394 - ETA: 2:05 - loss: 1.393 - ETA: 2:02 - loss: 1.394 - ETA: 2:00 - loss: 1.393 - ETA: 1:58 - loss: 1.393 - ETA: 1:56 - loss: 1.392 - ETA: 1:54 - loss: 1.391 - ETA: 1:52 - loss: 1.389 - ETA: 1:50 - loss: 1.388 - ETA: 1:48 - loss: 1.387 - ETA: 1:46 - loss: 1.387 - ETA: 1:44 - loss: 1.385 - ETA: 1:42 - loss: 1.385 - ETA: 1:40 - loss: 1.384 - ETA: 1:38 - loss: 1.384 - ETA: 1:36 - loss: 1.383 - ETA: 1:34 - loss: 1.381 - ETA: 1:32 - loss: 1.381 - ETA: 1:30 - loss: 1.381 - ETA: 1:28 - loss: 1.381 - ETA: 1:26 - loss: 1.380 - ETA: 1:24 - loss: 1.380 - ETA: 1:22 - loss: 1.379 - ETA: 1:20 - loss: 1.377 - ETA: 1:18 - loss: 1.376 - ETA: 1:16 - loss: 1.376 - ETA: 1:14 - loss: 1.375 - ETA: 1:12 - loss: 1.375 - ETA: 1:10 - loss: 1.374 - ETA: 1:08 - loss: 1.374 - ETA: 1:06 - loss: 1.375 - ETA: 1:04 - loss: 1.377 - ETA: 1:03 - loss: 1.377 - ETA: 1:01 - loss: 1.376 - ETA: 59s - loss: 1.376 - ETA: 57s - loss: 1.37 - ETA: 55s - loss: 1.37 - ETA: 53s - loss: 1.37 - ETA: 51s - loss: 1.37 - ETA: 49s - loss: 1.37 - ETA: 47s - loss: 1.37 - ETA: 45s - loss: 1.37 - ETA: 44s - loss: 1.37 - ETA: 42s - loss: 1.37 - ETA: 40s - loss: 1.37 - ETA: 38s - loss: 1.37 - ETA: 36s - loss: 1.37 - ETA: 34s - loss: 1.37 - ETA: 32s - loss: 1.37 - ETA: 31s - loss: 1.37 - ETA: 29s - loss: 1.37 - ETA: 27s - loss: 1.37 - ETA: 25s - loss: 1.36 - ETA: 23s - loss: 1.37 - ETA: 21s - loss: 1.37 - ETA: 19s - loss: 1.37 - ETA: 18s - loss: 1.37 - ETA: 16s - loss: 1.37 - ETA: 14s - loss: 1.37 - ETA: 12s - loss: 1.37 - ETA: 10s - loss: 1.36 - ETA: 9s - loss: 1.3697 - ETA: 7s - loss: 1.369 - ETA: 5s - loss: 1.368 - ETA: 3s - loss: 1.368 - ETA: 1s - loss: 1.368 - 339s 2s/step - loss: 1.3675 - val_loss: 1.5298\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.97949 to 1.52982, saving model to ./model_files/weights/VGG16_LSTM_Flickr8k_2l_32b_bn_dr_attn_bahdanau.hdf5\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:48 - loss: 1.499 - ETA: 4:47 - loss: 1.537 - ETA: 4:45 - loss: 1.474 - ETA: 4:43 - loss: 1.440 - ETA: 4:42 - loss: 1.414 - ETA: 4:40 - loss: 1.383 - ETA: 4:39 - loss: 1.347 - ETA: 4:37 - loss: 1.338 - ETA: 4:36 - loss: 1.348 - ETA: 4:34 - loss: 1.360 - ETA: 4:33 - loss: 1.340 - ETA: 4:31 - loss: 1.350 - ETA: 4:29 - loss: 1.337 - ETA: 4:28 - loss: 1.342 - ETA: 4:26 - loss: 1.339 - ETA: 4:25 - loss: 1.336 - ETA: 4:23 - loss: 1.336 - ETA: 4:22 - loss: 1.340 - ETA: 4:20 - loss: 1.342 - ETA: 4:19 - loss: 1.340 - ETA: 4:24 - loss: 1.333 - ETA: 4:35 - loss: 1.341 - ETA: 4:44 - loss: 1.342 - ETA: 4:53 - loss: 1.346 - ETA: 5:00 - loss: 1.342 - ETA: 5:05 - loss: 1.354 - ETA: 5:10 - loss: 1.355 - ETA: 5:14 - loss: 1.353 - ETA: 5:18 - loss: 1.345 - ETA: 5:21 - loss: 1.344 - ETA: 5:24 - loss: 1.345 - ETA: 5:26 - loss: 1.349 - ETA: 5:28 - loss: 1.346 - ETA: 5:30 - loss: 1.345 - ETA: 5:31 - loss: 1.346 - ETA: 5:28 - loss: 1.347 - ETA: 5:26 - loss: 1.342 - ETA: 5:23 - loss: 1.344 - ETA: 5:20 - loss: 1.339 - ETA: 5:17 - loss: 1.335 - ETA: 5:15 - loss: 1.342 - ETA: 5:12 - loss: 1.340 - ETA: 5:09 - loss: 1.340 - ETA: 5:07 - loss: 1.341 - ETA: 5:04 - loss: 1.341 - ETA: 5:01 - loss: 1.340 - ETA: 4:59 - loss: 1.337 - ETA: 4:56 - loss: 1.337 - ETA: 4:53 - loss: 1.337 - ETA: 4:51 - loss: 1.337 - ETA: 4:48 - loss: 1.338 - ETA: 4:45 - loss: 1.340 - ETA: 4:42 - loss: 1.338 - ETA: 4:39 - loss: 1.339 - ETA: 4:36 - loss: 1.343 - ETA: 4:33 - loss: 1.340 - ETA: 4:30 - loss: 1.339 - ETA: 4:28 - loss: 1.337 - ETA: 4:25 - loss: 1.336 - ETA: 4:22 - loss: 1.335 - ETA: 4:19 - loss: 1.336 - ETA: 4:16 - loss: 1.337 - ETA: 4:14 - loss: 1.339 - ETA: 4:11 - loss: 1.340 - ETA: 4:08 - loss: 1.340 - ETA: 4:06 - loss: 1.339 - ETA: 4:03 - loss: 1.339 - ETA: 4:00 - loss: 1.336 - ETA: 3:58 - loss: 1.331 - ETA: 3:55 - loss: 1.332 - ETA: 3:53 - loss: 1.333 - ETA: 3:50 - loss: 1.331 - ETA: 3:48 - loss: 1.333 - ETA: 3:45 - loss: 1.330 - ETA: 3:43 - loss: 1.328 - ETA: 3:40 - loss: 1.327 - ETA: 3:38 - loss: 1.328 - ETA: 3:36 - loss: 1.327 - ETA: 3:33 - loss: 1.325 - ETA: 3:31 - loss: 1.326 - ETA: 3:28 - loss: 1.324 - ETA: 3:26 - loss: 1.323 - ETA: 3:24 - loss: 1.323 - ETA: 3:21 - loss: 1.323 - ETA: 3:19 - loss: 1.323 - ETA: 3:17 - loss: 1.322 - ETA: 3:14 - loss: 1.322 - ETA: 3:12 - loss: 1.321 - ETA: 3:10 - loss: 1.320 - ETA: 3:08 - loss: 1.317 - ETA: 3:05 - loss: 1.318 - ETA: 3:03 - loss: 1.316 - ETA: 3:01 - loss: 1.315 - ETA: 2:59 - loss: 1.315 - ETA: 2:57 - loss: 1.312 - ETA: 2:54 - loss: 1.311 - ETA: 2:52 - loss: 1.312 - ETA: 2:50 - loss: 1.311 - ETA: 2:48 - loss: 1.312 - ETA: 2:46 - loss: 1.312 - ETA: 2:44 - loss: 1.313 - ETA: 2:41 - loss: 1.311 - ETA: 2:39 - loss: 1.309 - ETA: 2:37 - loss: 1.310 - ETA: 2:35 - loss: 1.311 - ETA: 2:33 - loss: 1.310 - ETA: 2:31 - loss: 1.308 - ETA: 2:29 - loss: 1.306 - ETA: 2:27 - loss: 1.308 - ETA: 2:25 - loss: 1.306 - ETA: 2:22 - loss: 1.306 - ETA: 2:20 - loss: 1.305 - ETA: 2:18 - loss: 1.306 - ETA: 2:16 - loss: 1.306 - ETA: 2:14 - loss: 1.306 - ETA: 2:12 - loss: 1.306 - ETA: 2:10 - loss: 1.305 - ETA: 2:08 - loss: 1.306 - ETA: 2:06 - loss: 1.305 - ETA: 2:04 - loss: 1.306 - ETA: 2:02 - loss: 1.306 - ETA: 2:00 - loss: 1.307 - ETA: 1:58 - loss: 1.307 - ETA: 1:56 - loss: 1.307 - ETA: 1:54 - loss: 1.307 - ETA: 1:52 - loss: 1.305 - ETA: 1:50 - loss: 1.305 - ETA: 1:48 - loss: 1.304 - ETA: 1:46 - loss: 1.303 - ETA: 1:44 - loss: 1.303 - ETA: 1:43 - loss: 1.302 - ETA: 1:41 - loss: 1.301 - ETA: 1:39 - loss: 1.300 - ETA: 1:37 - loss: 1.298 - ETA: 1:35 - loss: 1.298 - ETA: 1:33 - loss: 1.299 - ETA: 1:31 - loss: 1.298 - ETA: 1:29 - loss: 1.299 - ETA: 1:27 - loss: 1.299 - ETA: 1:25 - loss: 1.298 - ETA: 1:23 - loss: 1.298 - ETA: 1:21 - loss: 1.299 - ETA: 1:19 - loss: 1.299 - ETA: 1:18 - loss: 1.299 - ETA: 1:16 - loss: 1.298 - ETA: 1:14 - loss: 1.298 - ETA: 1:12 - loss: 1.298 - ETA: 1:10 - loss: 1.297 - ETA: 1:08 - loss: 1.298 - ETA: 1:06 - loss: 1.298 - ETA: 1:04 - loss: 1.297 - ETA: 1:03 - loss: 1.297 - ETA: 1:01 - loss: 1.298 - ETA: 59s - loss: 1.298 - ETA: 57s - loss: 1.29 - ETA: 55s - loss: 1.29 - ETA: 53s - loss: 1.29 - ETA: 51s - loss: 1.29 - ETA: 50s - loss: 1.29 - ETA: 48s - loss: 1.29 - ETA: 46s - loss: 1.29 - ETA: 44s - loss: 1.29 - ETA: 42s - loss: 1.29 - ETA: 40s - loss: 1.29 - ETA: 39s - loss: 1.29 - ETA: 37s - loss: 1.29 - ETA: 35s - loss: 1.29 - ETA: 33s - loss: 1.29 - ETA: 31s - loss: 1.29 - ETA: 30s - loss: 1.29 - ETA: 28s - loss: 1.29 - ETA: 26s - loss: 1.29 - ETA: 24s - loss: 1.29 - ETA: 22s - loss: 1.29 - ETA: 21s - loss: 1.29 - ETA: 19s - loss: 1.29 - ETA: 17s - loss: 1.29 - ETA: 15s - loss: 1.29 - ETA: 14s - loss: 1.29 - ETA: 12s - loss: 1.29 - ETA: 10s - loss: 1.29 - ETA: 8s - loss: 1.2961 - ETA: 7s - loss: 1.296 - ETA: 5s - loss: 1.295 - ETA: 3s - loss: 1.294 - ETA: 1s - loss: 1.293 - 330s 2s/step - loss: 1.2934 - val_loss: 2.6294\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.52982\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:47 - loss: 1.283 - ETA: 4:46 - loss: 1.321 - ETA: 4:45 - loss: 1.249 - ETA: 4:44 - loss: 1.307 - ETA: 4:42 - loss: 1.318 - ETA: 4:40 - loss: 1.307 - ETA: 4:39 - loss: 1.302 - ETA: 4:37 - loss: 1.278 - ETA: 4:36 - loss: 1.296 - ETA: 4:34 - loss: 1.297 - ETA: 4:33 - loss: 1.301 - ETA: 4:31 - loss: 1.302 - ETA: 4:30 - loss: 1.296 - ETA: 4:28 - loss: 1.289 - ETA: 4:26 - loss: 1.294 - ETA: 4:25 - loss: 1.284 - ETA: 4:23 - loss: 1.288 - ETA: 4:22 - loss: 1.283 - ETA: 4:20 - loss: 1.289 - ETA: 4:19 - loss: 1.299 - ETA: 4:17 - loss: 1.292 - ETA: 4:16 - loss: 1.287 - ETA: 4:14 - loss: 1.287 - ETA: 4:12 - loss: 1.289 - ETA: 4:11 - loss: 1.289 - ETA: 4:09 - loss: 1.284 - ETA: 4:31 - loss: 1.280 - ETA: 8:13 - loss: 1.284 - ETA: 8:08 - loss: 1.275 - ETA: 8:03 - loss: 1.276 - ETA: 7:58 - loss: 1.274 - ETA: 7:54 - loss: 1.277 - ETA: 7:49 - loss: 1.281 - ETA: 7:42 - loss: 1.278 - ETA: 7:34 - loss: 1.279 - ETA: 7:27 - loss: 1.276 - ETA: 7:20 - loss: 1.278 - ETA: 7:13 - loss: 1.274 - ETA: 7:06 - loss: 1.271 - ETA: 7:00 - loss: 1.269 - ETA: 6:54 - loss: 1.269 - ETA: 6:47 - loss: 1.269 - ETA: 6:41 - loss: 1.272 - ETA: 6:35 - loss: 1.269 - ETA: 6:28 - loss: 1.271 - ETA: 6:23 - loss: 1.271 - ETA: 6:17 - loss: 1.269 - ETA: 6:11 - loss: 1.268 - ETA: 6:06 - loss: 1.264 - ETA: 6:01 - loss: 1.262 - ETA: 5:55 - loss: 1.263 - ETA: 5:50 - loss: 1.266 - ETA: 5:45 - loss: 1.265 - ETA: 5:40 - loss: 1.267 - ETA: 5:36 - loss: 1.269 - ETA: 5:31 - loss: 1.268 - ETA: 5:26 - loss: 1.268 - ETA: 5:22 - loss: 1.267 - ETA: 5:18 - loss: 1.265 - ETA: 5:13 - loss: 1.267 - ETA: 5:09 - loss: 1.270 - ETA: 5:05 - loss: 1.272 - ETA: 5:01 - loss: 1.275 - ETA: 4:57 - loss: 1.277 - ETA: 4:53 - loss: 1.276 - ETA: 4:49 - loss: 1.277 - ETA: 4:46 - loss: 1.279 - ETA: 4:42 - loss: 1.277 - ETA: 4:38 - loss: 1.276 - ETA: 4:35 - loss: 1.276 - ETA: 4:31 - loss: 1.276 - ETA: 4:27 - loss: 1.276 - ETA: 4:24 - loss: 1.278 - ETA: 4:20 - loss: 1.277 - ETA: 4:17 - loss: 1.276 - ETA: 4:14 - loss: 1.277 - ETA: 4:10 - loss: 1.274 - ETA: 4:07 - loss: 1.273 - ETA: 4:04 - loss: 1.274 - ETA: 4:01 - loss: 1.278 - ETA: 3:58 - loss: 1.278 - ETA: 3:54 - loss: 1.278 - ETA: 3:51 - loss: 1.278 - ETA: 3:48 - loss: 1.277 - ETA: 3:46 - loss: 1.278 - ETA: 3:43 - loss: 1.278 - ETA: 3:40 - loss: 1.277 - ETA: 3:37 - loss: 1.277 - ETA: 3:34 - loss: 1.279 - ETA: 3:31 - loss: 1.278 - ETA: 3:29 - loss: 1.277 - ETA: 3:26 - loss: 1.276 - ETA: 3:23 - loss: 1.277 - ETA: 3:20 - loss: 1.278 - ETA: 3:18 - loss: 1.276 - ETA: 3:15 - loss: 1.276 - ETA: 3:13 - loss: 1.276 - ETA: 3:10 - loss: 1.276 - ETA: 3:07 - loss: 1.277 - ETA: 3:05 - loss: 1.277 - ETA: 3:02 - loss: 1.276 - ETA: 3:00 - loss: 1.277 - ETA: 2:57 - loss: 1.277 - ETA: 2:55 - loss: 1.277 - ETA: 2:52 - loss: 1.277 - ETA: 2:50 - loss: 1.278 - ETA: 2:47 - loss: 1.278 - ETA: 2:45 - loss: 1.279 - ETA: 2:43 - loss: 1.278 - ETA: 2:40 - loss: 1.276 - ETA: 2:38 - loss: 1.277 - ETA: 2:35 - loss: 1.277 - ETA: 2:33 - loss: 1.277 - ETA: 2:31 - loss: 1.278 - ETA: 2:28 - loss: 1.277 - ETA: 2:26 - loss: 1.277 - ETA: 2:23 - loss: 1.277 - ETA: 2:21 - loss: 1.279 - ETA: 2:19 - loss: 1.278 - ETA: 2:16 - loss: 1.277 - ETA: 2:14 - loss: 1.276 - ETA: 2:12 - loss: 1.276 - ETA: 2:10 - loss: 1.274 - ETA: 2:07 - loss: 1.276 - ETA: 2:05 - loss: 1.276 - ETA: 2:03 - loss: 1.275 - ETA: 2:01 - loss: 1.275 - ETA: 1:58 - loss: 1.275 - ETA: 1:56 - loss: 1.275 - ETA: 1:54 - loss: 1.275 - ETA: 1:52 - loss: 1.275 - ETA: 1:49 - loss: 1.274 - ETA: 1:47 - loss: 1.274 - ETA: 1:45 - loss: 1.274 - ETA: 1:43 - loss: 1.274 - ETA: 1:41 - loss: 1.274 - ETA: 1:39 - loss: 1.274 - ETA: 1:37 - loss: 1.275 - ETA: 1:34 - loss: 1.276 - ETA: 1:32 - loss: 1.277 - ETA: 1:30 - loss: 1.277 - ETA: 1:28 - loss: 1.277 - ETA: 1:26 - loss: 1.278 - ETA: 1:24 - loss: 1.277 - ETA: 1:22 - loss: 1.276 - ETA: 1:20 - loss: 1.275 - ETA: 1:18 - loss: 1.274 - ETA: 1:16 - loss: 1.273 - ETA: 1:14 - loss: 1.273 - ETA: 1:11 - loss: 1.272 - ETA: 1:09 - loss: 1.272 - ETA: 1:07 - loss: 1.272 - ETA: 1:05 - loss: 1.273 - ETA: 1:03 - loss: 1.273 - ETA: 1:01 - loss: 1.273 - ETA: 59s - loss: 1.272 - ETA: 57s - loss: 1.27 - ETA: 55s - loss: 1.27 - ETA: 53s - loss: 1.27 - ETA: 51s - loss: 1.26 - ETA: 49s - loss: 1.26 - ETA: 47s - loss: 1.26 - ETA: 45s - loss: 1.27 - ETA: 43s - loss: 1.27 - ETA: 42s - loss: 1.27 - ETA: 40s - loss: 1.27 - ETA: 38s - loss: 1.27 - ETA: 36s - loss: 1.27 - ETA: 34s - loss: 1.27 - ETA: 32s - loss: 1.27 - ETA: 30s - loss: 1.26 - ETA: 28s - loss: 1.27 - ETA: 26s - loss: 1.27 - ETA: 24s - loss: 1.27 - ETA: 22s - loss: 1.26 - ETA: 20s - loss: 1.26 - ETA: 18s - loss: 1.26 - ETA: 16s - loss: 1.26 - ETA: 15s - loss: 1.26 - ETA: 13s - loss: 1.26 - ETA: 11s - loss: 1.26 - ETA: 9s - loss: 1.2682 - ETA: 7s - loss: 1.268 - ETA: 5s - loss: 1.268 - ETA: 3s - loss: 1.267 - ETA: 1s - loss: 1.268 - 360s 2s/step - loss: 1.2666 - val_loss: 1.5076\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.52982 to 1.50758, saving model to ./model_files/weights/VGG16_LSTM_Flickr8k_2l_32b_bn_dr_attn_bahdanau.hdf5\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 9:31 - loss: 1.007 - ETA: 9:17 - loss: 1.111 - ETA: 9:14 - loss: 1.182 - ETA: 9:08 - loss: 1.168 - ETA: 9:06 - loss: 1.191 - ETA: 9:03 - loss: 1.221 - ETA: 9:00 - loss: 1.211 - ETA: 8:57 - loss: 1.224 - ETA: 8:55 - loss: 1.222 - ETA: 8:41 - loss: 1.220 - ETA: 8:23 - loss: 1.220 - ETA: 8:07 - loss: 1.225 - ETA: 7:54 - loss: 1.222 - ETA: 7:43 - loss: 1.234 - ETA: 7:33 - loss: 1.224 - ETA: 7:23 - loss: 1.238 - ETA: 7:15 - loss: 1.236 - ETA: 7:05 - loss: 1.244 - ETA: 6:57 - loss: 1.239 - ETA: 6:50 - loss: 1.237 - ETA: 6:43 - loss: 1.234 - ETA: 6:36 - loss: 1.236 - ETA: 6:30 - loss: 1.237 - ETA: 6:24 - loss: 1.242 - ETA: 6:19 - loss: 1.240 - ETA: 6:13 - loss: 1.235 - ETA: 6:07 - loss: 1.238 - ETA: 6:01 - loss: 1.241 - ETA: 5:56 - loss: 1.239 - ETA: 5:51 - loss: 1.235 - ETA: 5:47 - loss: 1.234 - ETA: 5:42 - loss: 1.237 - ETA: 5:38 - loss: 1.240 - ETA: 5:33 - loss: 1.243 - ETA: 5:29 - loss: 1.248 - ETA: 5:24 - loss: 1.249 - ETA: 5:20 - loss: 1.244 - ETA: 5:16 - loss: 1.244 - ETA: 5:12 - loss: 1.241 - ETA: 5:09 - loss: 1.235 - ETA: 5:05 - loss: 1.229 - ETA: 5:01 - loss: 1.229 - ETA: 4:58 - loss: 1.230 - ETA: 4:54 - loss: 1.235 - ETA: 4:51 - loss: 1.232 - ETA: 4:48 - loss: 1.227 - ETA: 4:44 - loss: 1.230 - ETA: 4:41 - loss: 1.228 - ETA: 4:38 - loss: 1.227 - ETA: 4:35 - loss: 1.227 - ETA: 4:32 - loss: 1.231 - ETA: 4:29 - loss: 1.234 - ETA: 4:26 - loss: 1.232 - ETA: 4:23 - loss: 1.232 - ETA: 4:21 - loss: 1.233 - ETA: 4:18 - loss: 1.234 - ETA: 4:15 - loss: 1.236 - ETA: 4:12 - loss: 1.236 - ETA: 4:09 - loss: 1.235 - ETA: 4:07 - loss: 1.236 - ETA: 4:04 - loss: 1.239 - ETA: 4:02 - loss: 1.237 - ETA: 3:59 - loss: 1.235 - ETA: 3:56 - loss: 1.233 - ETA: 3:54 - loss: 1.232 - ETA: 3:51 - loss: 1.230 - ETA: 3:49 - loss: 1.227 - ETA: 3:47 - loss: 1.227 - ETA: 3:44 - loss: 1.228 - ETA: 3:42 - loss: 1.229 - ETA: 3:39 - loss: 1.229 - ETA: 3:37 - loss: 1.231 - ETA: 3:35 - loss: 1.232 - ETA: 3:32 - loss: 1.231 - ETA: 3:30 - loss: 1.232 - ETA: 3:28 - loss: 1.233 - ETA: 3:26 - loss: 1.232 - ETA: 3:23 - loss: 1.231 - ETA: 3:21 - loss: 1.231 - ETA: 3:19 - loss: 1.231 - ETA: 3:17 - loss: 1.235 - ETA: 3:15 - loss: 1.235 - ETA: 3:12 - loss: 1.233 - ETA: 3:10 - loss: 1.233 - ETA: 3:08 - loss: 1.235 - ETA: 3:06 - loss: 1.236 - ETA: 3:04 - loss: 1.238 - ETA: 3:02 - loss: 1.237 - ETA: 3:00 - loss: 1.237 - ETA: 2:58 - loss: 1.238 - ETA: 2:55 - loss: 1.239 - ETA: 2:53 - loss: 1.240 - ETA: 2:51 - loss: 1.239 - ETA: 2:49 - loss: 1.242 - ETA: 2:47 - loss: 1.240 - ETA: 2:45 - loss: 1.240 - ETA: 2:43 - loss: 1.240 - ETA: 2:41 - loss: 1.242 - ETA: 2:39 - loss: 1.242 - ETA: 2:37 - loss: 1.244 - ETA: 2:35 - loss: 1.244 - ETA: 2:33 - loss: 1.245 - ETA: 2:31 - loss: 1.245 - ETA: 2:29 - loss: 1.244 - ETA: 2:27 - loss: 1.243 - ETA: 2:25 - loss: 1.244 - ETA: 2:23 - loss: 1.246 - ETA: 2:21 - loss: 1.243 - ETA: 2:19 - loss: 1.243 - ETA: 2:17 - loss: 1.242 - ETA: 2:15 - loss: 1.242 - ETA: 2:13 - loss: 1.241 - ETA: 2:11 - loss: 1.242 - ETA: 2:09 - loss: 1.242 - ETA: 2:07 - loss: 1.244 - ETA: 2:06 - loss: 1.244 - ETA: 2:04 - loss: 1.243 - ETA: 2:02 - loss: 1.243 - ETA: 2:00 - loss: 1.244 - ETA: 1:58 - loss: 1.243 - ETA: 1:56 - loss: 1.242 - ETA: 1:54 - loss: 1.244 - ETA: 1:52 - loss: 1.245 - ETA: 1:50 - loss: 1.245 - ETA: 1:49 - loss: 1.245 - ETA: 1:47 - loss: 1.245 - ETA: 1:45 - loss: 1.245 - ETA: 1:43 - loss: 1.244 - ETA: 1:41 - loss: 1.245 - ETA: 1:39 - loss: 1.245 - ETA: 1:37 - loss: 1.245 - ETA: 1:36 - loss: 1.245 - ETA: 1:34 - loss: 1.244 - ETA: 1:32 - loss: 1.245 - ETA: 1:30 - loss: 1.244 - ETA: 1:28 - loss: 1.244 - ETA: 1:27 - loss: 1.245 - ETA: 1:25 - loss: 1.246 - ETA: 1:23 - loss: 1.245 - ETA: 1:21 - loss: 1.246 - ETA: 1:19 - loss: 1.248 - ETA: 1:18 - loss: 1.248 - ETA: 1:16 - loss: 1.251 - ETA: 1:14 - loss: 1.251 - ETA: 1:12 - loss: 1.250 - ETA: 1:10 - loss: 1.251 - ETA: 1:09 - loss: 1.250 - ETA: 1:07 - loss: 1.250 - ETA: 1:05 - loss: 1.249 - ETA: 1:03 - loss: 1.248 - ETA: 1:02 - loss: 1.248 - ETA: 1:00 - loss: 1.248 - ETA: 58s - loss: 1.247 - ETA: 56s - loss: 1.24 - ETA: 54s - loss: 1.24 - ETA: 53s - loss: 1.24 - ETA: 51s - loss: 1.24 - ETA: 49s - loss: 1.24 - ETA: 48s - loss: 1.24 - ETA: 46s - loss: 1.24 - ETA: 44s - loss: 1.24 - ETA: 42s - loss: 1.24 - ETA: 41s - loss: 1.24 - ETA: 39s - loss: 1.24 - ETA: 37s - loss: 1.24 - ETA: 35s - loss: 1.24 - ETA: 34s - loss: 1.24 - ETA: 32s - loss: 1.24 - ETA: 30s - loss: 1.24 - ETA: 28s - loss: 1.24 - ETA: 27s - loss: 1.24 - ETA: 25s - loss: 1.24 - ETA: 23s - loss: 1.24 - ETA: 22s - loss: 1.24 - ETA: 20s - loss: 1.24 - ETA: 18s - loss: 1.24 - ETA: 16s - loss: 1.24 - ETA: 15s - loss: 1.24 - ETA: 13s - loss: 1.24 - ETA: 11s - loss: 1.24 - ETA: 10s - loss: 1.24 - ETA: 8s - loss: 1.2452 - ETA: 6s - loss: 1.245 - ETA: 5s - loss: 1.244 - ETA: 3s - loss: 1.245 - ETA: 1s - loss: 1.243 - 318s 2s/step - loss: 1.2437 - val_loss: 1.3879\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.50758 to 1.38787, saving model to ./model_files/weights/VGG16_LSTM_Flickr8k_2l_32b_bn_dr_attn_bahdanau.hdf5\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:47 - loss: 1.336 - ETA: 4:46 - loss: 1.293 - ETA: 4:44 - loss: 1.236 - ETA: 4:43 - loss: 1.226 - ETA: 4:41 - loss: 1.257 - ETA: 4:40 - loss: 1.267 - ETA: 4:38 - loss: 1.255 - ETA: 4:37 - loss: 1.256 - ETA: 4:35 - loss: 1.242 - ETA: 4:34 - loss: 1.238 - ETA: 4:32 - loss: 1.242 - ETA: 4:31 - loss: 1.240 - ETA: 4:29 - loss: 1.230 - ETA: 4:28 - loss: 1.230 - ETA: 4:26 - loss: 1.229 - ETA: 4:24 - loss: 1.227 - ETA: 4:23 - loss: 1.231 - ETA: 4:21 - loss: 1.231 - ETA: 4:20 - loss: 1.233 - ETA: 4:18 - loss: 1.233 - ETA: 4:17 - loss: 1.231 - ETA: 4:15 - loss: 1.238 - ETA: 4:14 - loss: 1.237 - ETA: 4:12 - loss: 1.236 - ETA: 4:11 - loss: 1.244 - ETA: 4:09 - loss: 1.242 - ETA: 4:07 - loss: 1.247 - ETA: 4:06 - loss: 1.241 - ETA: 4:04 - loss: 1.242 - ETA: 4:03 - loss: 1.245 - ETA: 4:01 - loss: 1.239 - ETA: 4:00 - loss: 1.236 - ETA: 3:58 - loss: 1.236 - ETA: 3:57 - loss: 1.236 - ETA: 3:55 - loss: 1.235 - ETA: 3:54 - loss: 1.233 - ETA: 3:52 - loss: 1.231 - ETA: 3:51 - loss: 1.226 - ETA: 3:49 - loss: 1.228 - ETA: 3:47 - loss: 1.225 - ETA: 3:46 - loss: 1.228 - ETA: 3:44 - loss: 1.231 - ETA: 3:43 - loss: 1.229 - ETA: 3:41 - loss: 1.224 - ETA: 3:40 - loss: 1.220 - ETA: 3:38 - loss: 1.218 - ETA: 3:37 - loss: 1.217 - ETA: 3:35 - loss: 1.221 - ETA: 3:34 - loss: 1.221 - ETA: 3:32 - loss: 1.220 - ETA: 3:30 - loss: 1.223 - ETA: 3:29 - loss: 1.222 - ETA: 3:27 - loss: 1.223 - ETA: 3:26 - loss: 1.224 - ETA: 3:24 - loss: 1.222 - ETA: 3:23 - loss: 1.218 - ETA: 3:21 - loss: 1.218 - ETA: 3:20 - loss: 1.219 - ETA: 3:18 - loss: 1.220 - ETA: 3:16 - loss: 1.220 - ETA: 3:15 - loss: 1.218 - ETA: 3:13 - loss: 1.217 - ETA: 3:12 - loss: 1.216 - ETA: 3:10 - loss: 1.216 - ETA: 3:09 - loss: 1.216 - ETA: 3:07 - loss: 1.215 - ETA: 3:06 - loss: 1.217 - ETA: 3:04 - loss: 1.215 - ETA: 3:02 - loss: 1.215 - ETA: 3:01 - loss: 1.215 - ETA: 2:59 - loss: 1.214 - ETA: 2:58 - loss: 1.214 - ETA: 2:56 - loss: 1.213 - ETA: 2:55 - loss: 1.211 - ETA: 2:53 - loss: 1.210 - ETA: 2:52 - loss: 1.209 - ETA: 2:50 - loss: 1.207 - ETA: 2:49 - loss: 1.207 - ETA: 2:47 - loss: 1.207 - ETA: 2:45 - loss: 1.207 - ETA: 2:44 - loss: 1.207 - ETA: 2:42 - loss: 1.204 - ETA: 2:41 - loss: 1.202 - ETA: 2:39 - loss: 1.203 - ETA: 2:38 - loss: 1.204 - ETA: 2:36 - loss: 1.203 - ETA: 2:35 - loss: 1.202 - ETA: 2:33 - loss: 1.203 - ETA: 2:31 - loss: 1.203 - ETA: 2:30 - loss: 1.203 - ETA: 2:28 - loss: 1.201 - ETA: 2:27 - loss: 1.202 - ETA: 2:25 - loss: 1.200 - ETA: 2:24 - loss: 1.202 - ETA: 2:22 - loss: 1.204 - ETA: 2:21 - loss: 1.204 - ETA: 2:19 - loss: 1.204 - ETA: 2:18 - loss: 1.203 - ETA: 2:16 - loss: 1.203 - ETA: 2:14 - loss: 1.204 - ETA: 2:13 - loss: 1.202 - ETA: 2:11 - loss: 1.202 - ETA: 2:10 - loss: 1.204 - ETA: 2:08 - loss: 1.203 - ETA: 2:07 - loss: 1.204 - ETA: 2:05 - loss: 1.203 - ETA: 2:04 - loss: 1.201 - ETA: 2:02 - loss: 1.201 - ETA: 2:00 - loss: 1.200 - ETA: 1:59 - loss: 1.201 - ETA: 1:57 - loss: 1.201 - ETA: 1:56 - loss: 1.202 - ETA: 1:54 - loss: 1.201 - ETA: 1:53 - loss: 1.203 - ETA: 1:51 - loss: 1.203 - ETA: 1:50 - loss: 1.203 - ETA: 1:48 - loss: 1.204 - ETA: 1:47 - loss: 1.204 - ETA: 1:45 - loss: 1.205 - ETA: 1:43 - loss: 1.204 - ETA: 1:42 - loss: 1.204 - ETA: 1:40 - loss: 1.204 - ETA: 1:39 - loss: 1.203 - ETA: 1:37 - loss: 1.204 - ETA: 1:36 - loss: 1.204 - ETA: 1:34 - loss: 1.204 - ETA: 1:33 - loss: 1.205 - ETA: 1:31 - loss: 1.206 - ETA: 1:29 - loss: 1.207 - ETA: 1:28 - loss: 1.207 - ETA: 1:26 - loss: 1.206 - ETA: 1:25 - loss: 1.206 - ETA: 1:23 - loss: 1.207 - ETA: 1:22 - loss: 1.208 - ETA: 1:20 - loss: 1.208 - ETA: 1:19 - loss: 1.208 - ETA: 1:17 - loss: 1.207 - ETA: 1:15 - loss: 1.209 - ETA: 1:14 - loss: 1.209 - ETA: 1:12 - loss: 1.208 - ETA: 1:11 - loss: 1.208 - ETA: 1:09 - loss: 1.208 - ETA: 1:08 - loss: 1.208 - ETA: 1:06 - loss: 1.209 - ETA: 1:05 - loss: 1.209 - ETA: 1:03 - loss: 1.210 - ETA: 1:02 - loss: 1.210 - ETA: 1:00 - loss: 1.211 - ETA: 58s - loss: 1.211 - ETA: 57s - loss: 1.21 - ETA: 55s - loss: 1.21 - ETA: 54s - loss: 1.21 - ETA: 52s - loss: 1.21 - ETA: 51s - loss: 1.21 - ETA: 49s - loss: 1.21 - ETA: 48s - loss: 1.21 - ETA: 46s - loss: 1.21 - ETA: 44s - loss: 1.21 - ETA: 43s - loss: 1.21 - ETA: 41s - loss: 1.21 - ETA: 43s - loss: 1.21 - ETA: 48s - loss: 1.21 - ETA: 48s - loss: 1.21 - ETA: 46s - loss: 1.21 - ETA: 44s - loss: 1.21 - ETA: 42s - loss: 1.21 - ETA: 40s - loss: 1.21 - ETA: 38s - loss: 1.21 - ETA: 36s - loss: 1.21 - ETA: 34s - loss: 1.21 - ETA: 32s - loss: 1.21 - ETA: 30s - loss: 1.21 - ETA: 28s - loss: 1.21 - ETA: 26s - loss: 1.21 - ETA: 24s - loss: 1.21 - ETA: 22s - loss: 1.21 - ETA: 20s - loss: 1.21 - ETA: 18s - loss: 1.21 - ETA: 16s - loss: 1.21 - ETA: 14s - loss: 1.21 - ETA: 12s - loss: 1.21 - ETA: 10s - loss: 1.21 - ETA: 8s - loss: 1.2101 - ETA: 6s - loss: 1.210 - ETA: 4s - loss: 1.211 - ETA: 2s - loss: 1.211 - 378s 2s/step - loss: 1.2122 - val_loss: 1.3936\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.38787\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 5:06 - loss: 1.298 - ETA: 5:06 - loss: 1.245 - ETA: 5:03 - loss: 1.244 - ETA: 5:01 - loss: 1.218 - ETA: 5:00 - loss: 1.216 - ETA: 4:58 - loss: 1.230 - ETA: 4:57 - loss: 1.222 - ETA: 4:55 - loss: 1.218 - ETA: 4:53 - loss: 1.209 - ETA: 4:52 - loss: 1.222 - ETA: 4:50 - loss: 1.221 - ETA: 4:48 - loss: 1.201 - ETA: 4:47 - loss: 1.195 - ETA: 4:45 - loss: 1.204 - ETA: 4:44 - loss: 1.201 - ETA: 4:42 - loss: 1.203 - ETA: 4:41 - loss: 1.209 - ETA: 4:39 - loss: 1.202 - ETA: 4:37 - loss: 1.200 - ETA: 4:36 - loss: 1.201 - ETA: 4:34 - loss: 1.203 - ETA: 4:32 - loss: 1.206 - ETA: 4:31 - loss: 1.201 - ETA: 4:29 - loss: 1.201 - ETA: 4:27 - loss: 1.195 - ETA: 4:26 - loss: 1.193 - ETA: 4:24 - loss: 1.197 - ETA: 4:22 - loss: 1.193 - ETA: 4:21 - loss: 1.195 - ETA: 4:19 - loss: 1.196 - ETA: 4:17 - loss: 1.197 - ETA: 4:15 - loss: 1.196 - ETA: 4:14 - loss: 1.194 - ETA: 4:12 - loss: 1.194 - ETA: 4:10 - loss: 1.198 - ETA: 4:08 - loss: 1.196 - ETA: 4:06 - loss: 1.199 - ETA: 4:05 - loss: 1.202 - ETA: 4:03 - loss: 1.204 - ETA: 4:01 - loss: 1.205 - ETA: 3:59 - loss: 1.204 - ETA: 3:57 - loss: 1.198 - ETA: 3:55 - loss: 1.195 - ETA: 3:53 - loss: 1.192 - ETA: 3:51 - loss: 1.190 - ETA: 3:49 - loss: 1.189 - ETA: 3:48 - loss: 1.187 - ETA: 3:46 - loss: 1.187 - ETA: 3:44 - loss: 1.184 - ETA: 3:42 - loss: 1.189 - ETA: 3:40 - loss: 1.189 - ETA: 3:38 - loss: 1.187 - ETA: 3:37 - loss: 1.187 - ETA: 3:35 - loss: 1.188 - ETA: 3:33 - loss: 1.191 - ETA: 3:31 - loss: 1.192 - ETA: 3:30 - loss: 1.193 - ETA: 3:28 - loss: 1.193 - ETA: 3:26 - loss: 1.190 - ETA: 3:24 - loss: 1.190 - ETA: 3:23 - loss: 1.187 - ETA: 3:21 - loss: 1.188 - ETA: 3:19 - loss: 1.190 - ETA: 3:17 - loss: 1.190 - ETA: 3:16 - loss: 1.187 - ETA: 3:14 - loss: 1.187 - ETA: 3:12 - loss: 1.188 - ETA: 3:11 - loss: 1.187 - ETA: 3:09 - loss: 1.185 - ETA: 3:07 - loss: 1.184 - ETA: 3:05 - loss: 1.184 - ETA: 3:04 - loss: 1.181 - ETA: 3:02 - loss: 1.179 - ETA: 3:00 - loss: 1.177 - ETA: 2:59 - loss: 1.175 - ETA: 2:57 - loss: 1.175 - ETA: 2:55 - loss: 1.176 - ETA: 2:54 - loss: 1.177 - ETA: 2:52 - loss: 1.179 - ETA: 2:50 - loss: 1.178 - ETA: 2:49 - loss: 1.180 - ETA: 2:47 - loss: 1.178 - ETA: 2:45 - loss: 1.178 - ETA: 2:44 - loss: 1.176 - ETA: 2:42 - loss: 1.175 - ETA: 2:41 - loss: 1.174 - ETA: 2:39 - loss: 1.177 - ETA: 2:37 - loss: 1.178 - ETA: 2:36 - loss: 1.178 - ETA: 2:34 - loss: 1.177 - ETA: 2:32 - loss: 1.175 - ETA: 2:31 - loss: 1.176 - ETA: 2:29 - loss: 1.179 - ETA: 2:27 - loss: 1.179 - ETA: 2:26 - loss: 1.179 - ETA: 2:24 - loss: 1.181 - ETA: 2:23 - loss: 1.181 - ETA: 2:21 - loss: 1.181 - ETA: 2:19 - loss: 1.180 - ETA: 2:18 - loss: 1.180 - ETA: 2:16 - loss: 1.178 - ETA: 2:14 - loss: 1.176 - ETA: 2:13 - loss: 1.177 - ETA: 2:11 - loss: 1.178 - ETA: 2:10 - loss: 1.180 - ETA: 2:08 - loss: 1.180 - ETA: 2:06 - loss: 1.181 - ETA: 2:05 - loss: 1.180 - ETA: 2:03 - loss: 1.180 - ETA: 2:02 - loss: 1.179 - ETA: 2:00 - loss: 1.178 - ETA: 1:58 - loss: 1.178 - ETA: 1:57 - loss: 1.179 - ETA: 1:55 - loss: 1.180 - ETA: 1:54 - loss: 1.180 - ETA: 1:52 - loss: 1.180 - ETA: 1:50 - loss: 1.179 - ETA: 1:49 - loss: 1.180 - ETA: 1:47 - loss: 1.178 - ETA: 1:45 - loss: 1.180 - ETA: 1:44 - loss: 1.179 - ETA: 1:42 - loss: 1.179 - ETA: 1:41 - loss: 1.181 - ETA: 1:39 - loss: 1.180 - ETA: 1:38 - loss: 1.182 - ETA: 1:36 - loss: 1.183 - ETA: 1:34 - loss: 1.183 - ETA: 1:33 - loss: 1.184 - ETA: 1:31 - loss: 1.184 - ETA: 1:30 - loss: 1.183 - ETA: 1:28 - loss: 1.183 - ETA: 1:26 - loss: 1.183 - ETA: 1:25 - loss: 1.184 - ETA: 1:23 - loss: 1.183 - ETA: 1:22 - loss: 1.184 - ETA: 1:20 - loss: 1.184 - ETA: 1:18 - loss: 1.184 - ETA: 1:17 - loss: 1.183 - ETA: 1:15 - loss: 1.183 - ETA: 1:14 - loss: 1.183 - ETA: 1:12 - loss: 1.183 - ETA: 1:10 - loss: 1.183 - ETA: 1:09 - loss: 1.183 - ETA: 1:07 - loss: 1.183 - ETA: 1:06 - loss: 1.183 - ETA: 1:04 - loss: 1.182 - ETA: 1:03 - loss: 1.183 - ETA: 1:01 - loss: 1.183 - ETA: 59s - loss: 1.183 - ETA: 58s - loss: 1.18 - ETA: 56s - loss: 1.18 - ETA: 55s - loss: 1.18 - ETA: 53s - loss: 1.18 - ETA: 51s - loss: 1.18 - ETA: 50s - loss: 1.18 - ETA: 48s - loss: 1.18 - ETA: 47s - loss: 1.18 - ETA: 45s - loss: 1.18 - ETA: 44s - loss: 1.18 - ETA: 42s - loss: 1.18 - ETA: 40s - loss: 1.18 - ETA: 39s - loss: 1.18 - ETA: 37s - loss: 1.18 - ETA: 36s - loss: 1.18 - ETA: 34s - loss: 1.18 - ETA: 33s - loss: 1.18 - ETA: 31s - loss: 1.18 - ETA: 29s - loss: 1.18 - ETA: 28s - loss: 1.18 - ETA: 26s - loss: 1.18 - ETA: 25s - loss: 1.18 - ETA: 23s - loss: 1.18 - ETA: 22s - loss: 1.18 - ETA: 20s - loss: 1.18 - ETA: 18s - loss: 1.18 - ETA: 17s - loss: 1.18 - ETA: 15s - loss: 1.18 - ETA: 14s - loss: 1.18 - ETA: 12s - loss: 1.18 - ETA: 10s - loss: 1.18 - ETA: 9s - loss: 1.1825 - ETA: 7s - loss: 1.182 - ETA: 6s - loss: 1.183 - ETA: 4s - loss: 1.182 - ETA: 3s - loss: 1.182 - ETA: 1s - loss: 1.181 - 296s 2s/step - loss: 1.1814 - val_loss: 1.4491\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.38787\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:48 - loss: 1.095 - ETA: 4:46 - loss: 1.060 - ETA: 4:44 - loss: 1.059 - ETA: 4:43 - loss: 1.109 - ETA: 4:41 - loss: 1.126 - ETA: 4:40 - loss: 1.134 - ETA: 4:39 - loss: 1.131 - ETA: 4:37 - loss: 1.136 - ETA: 4:36 - loss: 1.159 - ETA: 4:34 - loss: 1.147 - ETA: 4:33 - loss: 1.164 - ETA: 4:31 - loss: 1.168 - ETA: 4:29 - loss: 1.174 - ETA: 4:28 - loss: 1.164 - ETA: 4:26 - loss: 1.166 - ETA: 4:25 - loss: 1.159 - ETA: 4:23 - loss: 1.153 - ETA: 4:21 - loss: 1.156 - ETA: 4:20 - loss: 1.153 - ETA: 4:18 - loss: 1.150 - ETA: 4:17 - loss: 1.153 - ETA: 4:15 - loss: 1.150 - ETA: 4:14 - loss: 1.153 - ETA: 4:12 - loss: 1.160 - ETA: 4:11 - loss: 1.162 - ETA: 4:09 - loss: 1.163 - ETA: 4:07 - loss: 1.163 - ETA: 4:06 - loss: 1.159 - ETA: 4:04 - loss: 1.160 - ETA: 4:03 - loss: 1.155 - ETA: 4:01 - loss: 1.154 - ETA: 4:00 - loss: 1.156 - ETA: 3:58 - loss: 1.159 - ETA: 3:57 - loss: 1.159 - ETA: 3:55 - loss: 1.157 - ETA: 3:54 - loss: 1.155 - ETA: 3:52 - loss: 1.151 - ETA: 3:50 - loss: 1.153 - ETA: 3:49 - loss: 1.149 - ETA: 3:47 - loss: 1.149 - ETA: 3:46 - loss: 1.146 - ETA: 3:44 - loss: 1.145 - ETA: 3:43 - loss: 1.147 - ETA: 3:41 - loss: 1.149 - ETA: 3:40 - loss: 1.148 - ETA: 3:38 - loss: 1.145 - ETA: 3:36 - loss: 1.144 - ETA: 3:35 - loss: 1.145 - ETA: 3:33 - loss: 1.146 - ETA: 3:32 - loss: 1.143 - ETA: 3:30 - loss: 1.141 - ETA: 3:29 - loss: 1.142 - ETA: 3:27 - loss: 1.144 - ETA: 3:26 - loss: 1.145 - ETA: 3:24 - loss: 1.148 - ETA: 3:23 - loss: 1.148 - ETA: 3:21 - loss: 1.144 - ETA: 3:19 - loss: 1.147 - ETA: 3:18 - loss: 1.146 - ETA: 3:16 - loss: 1.146 - ETA: 3:15 - loss: 1.146 - ETA: 3:13 - loss: 1.146 - ETA: 3:12 - loss: 1.147 - ETA: 3:10 - loss: 1.154 - ETA: 3:09 - loss: 1.151 - ETA: 3:07 - loss: 1.150 - ETA: 3:05 - loss: 1.150 - ETA: 3:04 - loss: 1.150 - ETA: 3:02 - loss: 1.150 - ETA: 3:01 - loss: 1.149 - ETA: 2:59 - loss: 1.150 - ETA: 2:58 - loss: 1.150 - ETA: 2:56 - loss: 1.150 - ETA: 2:55 - loss: 1.149 - ETA: 2:53 - loss: 1.147 - ETA: 2:52 - loss: 1.146 - ETA: 2:50 - loss: 1.145 - ETA: 2:48 - loss: 1.143 - ETA: 2:47 - loss: 1.142 - ETA: 2:45 - loss: 1.142 - ETA: 2:44 - loss: 1.142 - ETA: 2:42 - loss: 1.140 - ETA: 2:41 - loss: 1.139 - ETA: 2:39 - loss: 1.140 - ETA: 2:38 - loss: 1.140 - ETA: 2:36 - loss: 1.141 - ETA: 2:34 - loss: 1.142 - ETA: 2:33 - loss: 1.144 - ETA: 2:31 - loss: 1.141 - ETA: 2:30 - loss: 1.141 - ETA: 2:28 - loss: 1.139 - ETA: 2:27 - loss: 1.139 - ETA: 2:25 - loss: 1.138 - ETA: 2:24 - loss: 1.136 - ETA: 2:22 - loss: 1.136 - ETA: 2:21 - loss: 1.138 - ETA: 2:19 - loss: 1.138 - ETA: 2:17 - loss: 1.137 - ETA: 2:16 - loss: 1.137 - ETA: 2:14 - loss: 1.137 - ETA: 2:13 - loss: 1.138 - ETA: 2:11 - loss: 1.136 - ETA: 2:10 - loss: 1.136 - ETA: 2:08 - loss: 1.137 - ETA: 2:07 - loss: 1.135 - ETA: 2:05 - loss: 1.135 - ETA: 2:03 - loss: 1.135 - ETA: 2:02 - loss: 1.137 - ETA: 2:00 - loss: 1.139 - ETA: 1:59 - loss: 1.140 - ETA: 1:57 - loss: 1.139 - ETA: 1:56 - loss: 1.141 - ETA: 1:54 - loss: 1.141 - ETA: 1:53 - loss: 1.140 - ETA: 1:51 - loss: 1.139 - ETA: 1:50 - loss: 1.140 - ETA: 1:48 - loss: 1.140 - ETA: 1:46 - loss: 1.141 - ETA: 1:45 - loss: 1.140 - ETA: 1:43 - loss: 1.141 - ETA: 1:42 - loss: 1.142 - ETA: 1:40 - loss: 1.142 - ETA: 1:39 - loss: 1.143 - ETA: 1:37 - loss: 1.143 - ETA: 1:36 - loss: 1.144 - ETA: 1:34 - loss: 1.145 - ETA: 1:33 - loss: 1.147 - ETA: 1:31 - loss: 1.146 - ETA: 1:29 - loss: 1.146 - ETA: 1:28 - loss: 1.146 - ETA: 1:26 - loss: 1.146 - ETA: 1:25 - loss: 1.145 - ETA: 1:23 - loss: 1.146 - ETA: 1:22 - loss: 1.145 - ETA: 1:20 - loss: 1.146 - ETA: 1:19 - loss: 1.147 - ETA: 1:17 - loss: 1.146 - ETA: 1:15 - loss: 1.147 - ETA: 1:14 - loss: 1.147 - ETA: 1:12 - loss: 1.148 - ETA: 1:11 - loss: 1.146 - ETA: 1:09 - loss: 1.146 - ETA: 1:08 - loss: 1.146 - ETA: 1:06 - loss: 1.146 - ETA: 1:05 - loss: 1.146 - ETA: 1:03 - loss: 1.145 - ETA: 1:02 - loss: 1.145 - ETA: 1:00 - loss: 1.145 - ETA: 58s - loss: 1.146 - ETA: 57s - loss: 1.14 - ETA: 55s - loss: 1.14 - ETA: 54s - loss: 1.14 - ETA: 52s - loss: 1.14 - ETA: 51s - loss: 1.14 - ETA: 49s - loss: 1.14 - ETA: 48s - loss: 1.14 - ETA: 46s - loss: 1.14 - ETA: 44s - loss: 1.14 - ETA: 43s - loss: 1.14 - ETA: 41s - loss: 1.14 - ETA: 40s - loss: 1.14 - ETA: 38s - loss: 1.14 - ETA: 37s - loss: 1.14 - ETA: 35s - loss: 1.14 - ETA: 34s - loss: 1.14 - ETA: 32s - loss: 1.14 - ETA: 31s - loss: 1.14 - ETA: 29s - loss: 1.14 - ETA: 27s - loss: 1.14 - ETA: 26s - loss: 1.14 - ETA: 24s - loss: 1.14 - ETA: 23s - loss: 1.14 - ETA: 21s - loss: 1.14 - ETA: 20s - loss: 1.14 - ETA: 18s - loss: 1.14 - ETA: 17s - loss: 1.14 - ETA: 15s - loss: 1.14 - ETA: 13s - loss: 1.14 - ETA: 12s - loss: 1.14 - ETA: 10s - loss: 1.14 - ETA: 9s - loss: 1.1407 - ETA: 7s - loss: 1.140 - ETA: 6s - loss: 1.139 - ETA: 4s - loss: 1.139 - ETA: 3s - loss: 1.139 - ETA: 1s - loss: 1.139 - 292s 2s/step - loss: 1.1393 - val_loss: 1.3908\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.38787\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:47 - loss: 0.827 - ETA: 4:46 - loss: 1.026 - ETA: 4:44 - loss: 1.030 - ETA: 4:43 - loss: 1.066 - ETA: 4:41 - loss: 1.103 - ETA: 7:49 - loss: 1.121 - ETA: 26:59 - loss: 1.13 - ETA: 31:42 - loss: 1.12 - ETA: 28:44 - loss: 1.12 - ETA: 26:20 - loss: 1.13 - ETA: 24:23 - loss: 1.13 - ETA: 22:44 - loss: 1.13 - ETA: 21:20 - loss: 1.13 - ETA: 20:08 - loss: 1.12 - ETA: 19:04 - loss: 1.13 - ETA: 18:06 - loss: 1.14 - ETA: 17:13 - loss: 1.15 - ETA: 16:27 - loss: 1.15 - ETA: 15:45 - loss: 1.15 - ETA: 15:07 - loss: 1.15 - ETA: 14:32 - loss: 1.15 - ETA: 14:01 - loss: 1.15 - ETA: 13:32 - loss: 1.15 - ETA: 13:05 - loss: 1.15 - ETA: 12:40 - loss: 1.15 - ETA: 12:18 - loss: 1.14 - ETA: 11:56 - loss: 1.14 - ETA: 11:36 - loss: 1.13 - ETA: 11:18 - loss: 1.13 - ETA: 11:00 - loss: 1.13 - ETA: 10:43 - loss: 1.13 - ETA: 10:28 - loss: 1.12 - ETA: 10:12 - loss: 1.12 - ETA: 9:58 - loss: 1.1247 - ETA: 9:44 - loss: 1.127 - ETA: 9:31 - loss: 1.133 - ETA: 9:19 - loss: 1.134 - ETA: 9:07 - loss: 1.137 - ETA: 8:56 - loss: 1.137 - ETA: 8:45 - loss: 1.141 - ETA: 8:34 - loss: 1.141 - ETA: 8:24 - loss: 1.140 - ETA: 8:15 - loss: 1.138 - ETA: 8:06 - loss: 1.137 - ETA: 7:57 - loss: 1.139 - ETA: 7:48 - loss: 1.140 - ETA: 7:40 - loss: 1.144 - ETA: 7:32 - loss: 1.142 - ETA: 7:24 - loss: 1.140 - ETA: 7:17 - loss: 1.142 - ETA: 7:09 - loss: 1.144 - ETA: 7:02 - loss: 1.141 - ETA: 6:55 - loss: 1.141 - ETA: 6:49 - loss: 1.139 - ETA: 6:42 - loss: 1.137 - ETA: 6:36 - loss: 1.139 - ETA: 6:30 - loss: 1.141 - ETA: 6:24 - loss: 1.142 - ETA: 6:18 - loss: 1.140 - ETA: 6:12 - loss: 1.140 - ETA: 6:07 - loss: 1.140 - ETA: 6:01 - loss: 1.137 - ETA: 5:56 - loss: 1.136 - ETA: 5:50 - loss: 1.136 - ETA: 5:45 - loss: 1.132 - ETA: 5:40 - loss: 1.134 - ETA: 5:35 - loss: 1.134 - ETA: 5:30 - loss: 1.134 - ETA: 5:25 - loss: 1.131 - ETA: 5:21 - loss: 1.130 - ETA: 5:16 - loss: 1.130 - ETA: 5:12 - loss: 1.129 - ETA: 5:07 - loss: 1.130 - ETA: 5:03 - loss: 1.130 - ETA: 4:59 - loss: 1.131 - ETA: 4:54 - loss: 1.131 - ETA: 4:50 - loss: 1.130 - ETA: 4:46 - loss: 1.131 - ETA: 4:42 - loss: 1.129 - ETA: 4:38 - loss: 1.128 - ETA: 4:34 - loss: 1.129 - ETA: 4:30 - loss: 1.129 - ETA: 4:26 - loss: 1.130 - ETA: 4:22 - loss: 1.131 - ETA: 4:19 - loss: 1.131 - ETA: 4:15 - loss: 1.130 - ETA: 4:11 - loss: 1.130 - ETA: 4:08 - loss: 1.130 - ETA: 4:04 - loss: 1.129 - ETA: 4:01 - loss: 1.128 - ETA: 3:57 - loss: 1.128 - ETA: 3:54 - loss: 1.126 - ETA: 3:50 - loss: 1.127 - ETA: 3:47 - loss: 1.126 - ETA: 3:44 - loss: 1.123 - ETA: 3:40 - loss: 1.122 - ETA: 3:37 - loss: 1.121 - ETA: 3:34 - loss: 1.121 - ETA: 3:31 - loss: 1.121 - ETA: 3:28 - loss: 1.123 - ETA: 3:24 - loss: 1.124 - ETA: 3:21 - loss: 1.123 - ETA: 3:18 - loss: 1.123 - ETA: 3:15 - loss: 1.123 - ETA: 3:12 - loss: 1.122 - ETA: 3:09 - loss: 1.122 - ETA: 3:06 - loss: 1.123 - ETA: 3:04 - loss: 1.122 - ETA: 3:01 - loss: 1.120 - ETA: 2:58 - loss: 1.121 - ETA: 2:55 - loss: 1.122 - ETA: 2:52 - loss: 1.120 - ETA: 2:49 - loss: 1.120 - ETA: 2:47 - loss: 1.121 - ETA: 2:44 - loss: 1.121 - ETA: 2:41 - loss: 1.121 - ETA: 2:38 - loss: 1.122 - ETA: 2:36 - loss: 1.121 - ETA: 2:33 - loss: 1.121 - ETA: 2:30 - loss: 1.121 - ETA: 2:28 - loss: 1.121 - ETA: 2:25 - loss: 1.120 - ETA: 2:23 - loss: 1.121 - ETA: 2:20 - loss: 1.120 - ETA: 2:17 - loss: 1.119 - ETA: 2:15 - loss: 1.119 - ETA: 2:12 - loss: 1.119 - ETA: 2:10 - loss: 1.119 - ETA: 2:07 - loss: 1.121 - ETA: 2:05 - loss: 1.120 - ETA: 2:02 - loss: 1.119 - ETA: 2:00 - loss: 1.119 - ETA: 1:57 - loss: 1.119 - ETA: 1:55 - loss: 1.118 - ETA: 1:53 - loss: 1.116 - ETA: 1:50 - loss: 1.117 - ETA: 1:48 - loss: 1.117 - ETA: 1:45 - loss: 1.117 - ETA: 1:43 - loss: 1.117 - ETA: 1:41 - loss: 1.117 - ETA: 1:38 - loss: 1.116 - ETA: 1:36 - loss: 1.118 - ETA: 1:34 - loss: 1.118 - ETA: 1:31 - loss: 1.119 - ETA: 1:29 - loss: 1.118 - ETA: 1:27 - loss: 1.119 - ETA: 1:24 - loss: 1.118 - ETA: 1:22 - loss: 1.117 - ETA: 1:20 - loss: 1.117 - ETA: 1:18 - loss: 1.116 - ETA: 1:15 - loss: 1.115 - ETA: 1:13 - loss: 1.115 - ETA: 1:11 - loss: 1.116 - ETA: 1:09 - loss: 1.116 - ETA: 1:06 - loss: 1.115 - ETA: 1:04 - loss: 1.114 - ETA: 1:02 - loss: 1.114 - ETA: 1:00 - loss: 1.114 - ETA: 58s - loss: 1.114 - ETA: 56s - loss: 1.11 - ETA: 53s - loss: 1.11 - ETA: 51s - loss: 1.11 - ETA: 49s - loss: 1.11 - ETA: 47s - loss: 1.11 - ETA: 45s - loss: 1.11 - ETA: 43s - loss: 1.11 - ETA: 41s - loss: 1.11 - ETA: 38s - loss: 1.11 - ETA: 36s - loss: 1.11 - ETA: 34s - loss: 1.11 - ETA: 32s - loss: 1.11 - ETA: 30s - loss: 1.11 - ETA: 28s - loss: 1.11 - ETA: 26s - loss: 1.11 - ETA: 24s - loss: 1.11 - ETA: 22s - loss: 1.11 - ETA: 20s - loss: 1.11 - ETA: 18s - loss: 1.11 - ETA: 16s - loss: 1.11 - ETA: 14s - loss: 1.11 - ETA: 12s - loss: 1.11 - ETA: 10s - loss: 1.11 - ETA: 8s - loss: 1.1122 - ETA: 6s - loss: 1.112 - ETA: 4s - loss: 1.113 - ETA: 2s - loss: 1.112 - 376s 2s/step - loss: 1.1125 - val_loss: 1.3665\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.38787 to 1.36652, saving model to ./model_files/weights/VGG16_LSTM_Flickr8k_2l_32b_bn_dr_attn_bahdanau.hdf5\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:47 - loss: 1.228 - ETA: 4:46 - loss: 1.181 - ETA: 4:44 - loss: 1.179 - ETA: 4:43 - loss: 1.149 - ETA: 4:41 - loss: 1.122 - ETA: 4:40 - loss: 1.091 - ETA: 4:38 - loss: 1.105 - ETA: 4:37 - loss: 1.101 - ETA: 4:35 - loss: 1.096 - ETA: 4:34 - loss: 1.107 - ETA: 4:32 - loss: 1.122 - ETA: 4:30 - loss: 1.125 - ETA: 4:29 - loss: 1.115 - ETA: 4:27 - loss: 1.120 - ETA: 4:26 - loss: 1.119 - ETA: 4:24 - loss: 1.135 - ETA: 4:23 - loss: 1.129 - ETA: 4:21 - loss: 1.135 - ETA: 4:20 - loss: 1.134 - ETA: 4:18 - loss: 1.137 - ETA: 4:17 - loss: 1.140 - ETA: 4:15 - loss: 1.133 - ETA: 4:14 - loss: 1.130 - ETA: 4:12 - loss: 1.130 - ETA: 4:11 - loss: 1.126 - ETA: 4:09 - loss: 1.127 - ETA: 4:07 - loss: 1.130 - ETA: 4:06 - loss: 1.127 - ETA: 4:04 - loss: 1.131 - ETA: 4:03 - loss: 1.130 - ETA: 4:01 - loss: 1.126 - ETA: 4:00 - loss: 1.122 - ETA: 3:58 - loss: 1.125 - ETA: 3:57 - loss: 1.124 - ETA: 3:55 - loss: 1.123 - ETA: 3:53 - loss: 1.119 - ETA: 3:52 - loss: 1.117 - ETA: 3:50 - loss: 1.115 - ETA: 3:49 - loss: 1.119 - ETA: 3:47 - loss: 1.114 - ETA: 3:46 - loss: 1.115 - ETA: 3:44 - loss: 1.117 - ETA: 3:43 - loss: 1.114 - ETA: 3:41 - loss: 1.116 - ETA: 3:40 - loss: 1.113 - ETA: 3:38 - loss: 1.114 - ETA: 3:36 - loss: 1.113 - ETA: 3:35 - loss: 1.113 - ETA: 3:33 - loss: 1.115 - ETA: 3:32 - loss: 1.115 - ETA: 3:30 - loss: 1.114 - ETA: 3:29 - loss: 1.114 - ETA: 3:27 - loss: 1.112 - ETA: 3:26 - loss: 1.114 - ETA: 3:24 - loss: 1.113 - ETA: 3:23 - loss: 1.110 - ETA: 3:21 - loss: 1.110 - ETA: 3:20 - loss: 1.112 - ETA: 3:18 - loss: 1.110 - ETA: 3:16 - loss: 1.111 - ETA: 3:15 - loss: 1.108 - ETA: 3:13 - loss: 1.108 - ETA: 3:12 - loss: 1.107 - ETA: 3:10 - loss: 1.106 - ETA: 3:09 - loss: 1.102 - ETA: 3:07 - loss: 1.105 - ETA: 3:06 - loss: 1.106 - ETA: 3:04 - loss: 1.107 - ETA: 3:02 - loss: 1.108 - ETA: 3:01 - loss: 1.108 - ETA: 2:59 - loss: 1.107 - ETA: 2:58 - loss: 1.105 - ETA: 2:56 - loss: 1.102 - ETA: 2:55 - loss: 1.103 - ETA: 2:53 - loss: 1.105 - ETA: 2:52 - loss: 1.104 - ETA: 2:50 - loss: 1.106 - ETA: 2:49 - loss: 1.104 - ETA: 2:47 - loss: 1.103 - ETA: 2:45 - loss: 1.101 - ETA: 2:44 - loss: 1.100 - ETA: 2:42 - loss: 1.101 - ETA: 2:41 - loss: 1.101 - ETA: 2:39 - loss: 1.100 - ETA: 2:38 - loss: 1.100 - ETA: 2:36 - loss: 1.099 - ETA: 2:35 - loss: 1.100 - ETA: 2:33 - loss: 1.100 - ETA: 2:31 - loss: 1.098 - ETA: 2:30 - loss: 1.097 - ETA: 2:28 - loss: 1.097 - ETA: 2:27 - loss: 1.099 - ETA: 2:25 - loss: 1.100 - ETA: 2:24 - loss: 1.100 - ETA: 2:22 - loss: 1.100 - ETA: 2:21 - loss: 1.099 - ETA: 2:19 - loss: 1.099 - ETA: 2:17 - loss: 1.098 - ETA: 2:16 - loss: 1.098 - ETA: 2:14 - loss: 1.096 - ETA: 2:13 - loss: 1.098 - ETA: 2:11 - loss: 1.097 - ETA: 2:10 - loss: 1.096 - ETA: 2:08 - loss: 1.095 - ETA: 2:07 - loss: 1.094 - ETA: 2:05 - loss: 1.093 - ETA: 2:04 - loss: 1.091 - ETA: 2:02 - loss: 1.091 - ETA: 2:00 - loss: 1.091 - ETA: 1:59 - loss: 1.090 - ETA: 1:57 - loss: 1.088 - ETA: 1:56 - loss: 1.087 - ETA: 1:54 - loss: 1.088 - ETA: 1:53 - loss: 1.089 - ETA: 1:51 - loss: 1.090 - ETA: 1:50 - loss: 1.091 - ETA: 1:48 - loss: 1.092 - ETA: 1:46 - loss: 1.090 - ETA: 1:45 - loss: 1.090 - ETA: 1:43 - loss: 1.090 - ETA: 1:42 - loss: 1.090 - ETA: 1:40 - loss: 1.090 - ETA: 1:39 - loss: 1.089 - ETA: 1:37 - loss: 1.089 - ETA: 1:36 - loss: 1.089 - ETA: 1:34 - loss: 1.089 - ETA: 1:33 - loss: 1.090 - ETA: 1:31 - loss: 1.091 - ETA: 1:29 - loss: 1.091 - ETA: 1:28 - loss: 1.093 - ETA: 1:26 - loss: 1.093 - ETA: 1:25 - loss: 1.091 - ETA: 1:23 - loss: 1.091 - ETA: 1:22 - loss: 1.091 - ETA: 1:20 - loss: 1.090 - ETA: 1:19 - loss: 1.090 - ETA: 1:17 - loss: 1.092 - ETA: 1:15 - loss: 1.092 - ETA: 1:14 - loss: 1.092 - ETA: 1:12 - loss: 1.092 - ETA: 1:11 - loss: 1.091 - ETA: 1:09 - loss: 1.092 - ETA: 1:08 - loss: 1.092 - ETA: 1:06 - loss: 1.093 - ETA: 1:05 - loss: 1.093 - ETA: 1:03 - loss: 1.094 - ETA: 1:02 - loss: 1.094 - ETA: 1:00 - loss: 1.094 - ETA: 58s - loss: 1.093 - ETA: 57s - loss: 1.09 - ETA: 55s - loss: 1.09 - ETA: 54s - loss: 1.09 - ETA: 52s - loss: 1.09 - ETA: 51s - loss: 1.09 - ETA: 49s - loss: 1.09 - ETA: 48s - loss: 1.09 - ETA: 46s - loss: 1.09 - ETA: 44s - loss: 1.09 - ETA: 43s - loss: 1.09 - ETA: 41s - loss: 1.09 - ETA: 40s - loss: 1.09 - ETA: 38s - loss: 1.09 - ETA: 37s - loss: 1.09 - ETA: 35s - loss: 1.09 - ETA: 34s - loss: 1.09 - ETA: 32s - loss: 1.09 - ETA: 31s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 27s - loss: 1.09 - ETA: 26s - loss: 1.09 - ETA: 24s - loss: 1.09 - ETA: 23s - loss: 1.09 - ETA: 21s - loss: 1.09 - ETA: 20s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0915 - ETA: 7s - loss: 1.090 - ETA: 6s - loss: 1.090 - ETA: 4s - loss: 1.090 - ETA: 3s - loss: 1.091 - ETA: 1s - loss: 1.091 - 292s 2s/step - loss: 1.0916 - val_loss: 1.4164\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.36652\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:47 - loss: 1.335 - ETA: 4:46 - loss: 1.235 - ETA: 4:45 - loss: 1.195 - ETA: 4:43 - loss: 1.199 - ETA: 4:42 - loss: 1.179 - ETA: 4:40 - loss: 1.157 - ETA: 4:39 - loss: 1.142 - ETA: 4:37 - loss: 1.139 - ETA: 4:35 - loss: 1.135 - ETA: 4:34 - loss: 1.136 - ETA: 4:32 - loss: 1.112 - ETA: 4:31 - loss: 1.112 - ETA: 4:29 - loss: 1.120 - ETA: 4:28 - loss: 1.114 - ETA: 4:26 - loss: 1.106 - ETA: 4:25 - loss: 1.107 - ETA: 4:23 - loss: 1.118 - ETA: 4:22 - loss: 1.119 - ETA: 4:20 - loss: 1.123 - ETA: 4:19 - loss: 1.119 - ETA: 4:17 - loss: 1.128 - ETA: 4:16 - loss: 1.131 - ETA: 4:14 - loss: 1.126 - ETA: 4:12 - loss: 1.127 - ETA: 4:11 - loss: 1.132 - ETA: 4:09 - loss: 1.128 - ETA: 4:08 - loss: 1.122 - ETA: 4:06 - loss: 1.122 - ETA: 4:05 - loss: 1.128 - ETA: 4:03 - loss: 1.121 - ETA: 4:02 - loss: 1.125 - ETA: 4:00 - loss: 1.124 - ETA: 3:58 - loss: 1.122 - ETA: 3:57 - loss: 1.125 - ETA: 3:55 - loss: 1.130 - ETA: 3:54 - loss: 1.133 - ETA: 3:52 - loss: 1.137 - ETA: 3:51 - loss: 1.134 - ETA: 3:49 - loss: 1.131 - ETA: 3:48 - loss: 1.128 - ETA: 3:46 - loss: 1.125 - ETA: 3:44 - loss: 1.125 - ETA: 3:43 - loss: 1.123 - ETA: 3:41 - loss: 1.122 - ETA: 3:40 - loss: 1.124 - ETA: 3:38 - loss: 1.128 - ETA: 3:37 - loss: 1.128 - ETA: 3:35 - loss: 1.126 - ETA: 3:34 - loss: 1.125 - ETA: 3:32 - loss: 1.121 - ETA: 3:30 - loss: 1.120 - ETA: 3:29 - loss: 1.118 - ETA: 3:27 - loss: 1.115 - ETA: 3:26 - loss: 1.116 - ETA: 3:24 - loss: 1.116 - ETA: 3:23 - loss: 1.115 - ETA: 3:21 - loss: 1.114 - ETA: 3:20 - loss: 1.118 - ETA: 3:18 - loss: 1.118 - ETA: 3:16 - loss: 1.121 - ETA: 3:15 - loss: 1.120 - ETA: 3:13 - loss: 1.116 - ETA: 3:12 - loss: 1.116 - ETA: 3:10 - loss: 1.116 - ETA: 3:09 - loss: 1.115 - ETA: 3:07 - loss: 1.112 - ETA: 3:06 - loss: 1.112 - ETA: 3:04 - loss: 1.111 - ETA: 3:03 - loss: 1.112 - ETA: 3:01 - loss: 1.109 - ETA: 2:59 - loss: 1.107 - ETA: 2:58 - loss: 1.106 - ETA: 2:56 - loss: 1.105 - ETA: 2:55 - loss: 1.104 - ETA: 2:53 - loss: 1.104 - ETA: 2:52 - loss: 1.104 - ETA: 2:50 - loss: 1.105 - ETA: 2:49 - loss: 1.106 - ETA: 2:47 - loss: 1.106 - ETA: 2:45 - loss: 1.106 - ETA: 2:44 - loss: 1.105 - ETA: 2:42 - loss: 1.106 - ETA: 2:41 - loss: 1.107 - ETA: 2:39 - loss: 1.106 - ETA: 2:38 - loss: 1.107 - ETA: 2:36 - loss: 1.107 - ETA: 2:35 - loss: 1.106 - ETA: 2:33 - loss: 1.103 - ETA: 2:31 - loss: 1.102 - ETA: 2:30 - loss: 1.101 - ETA: 2:28 - loss: 1.101 - ETA: 2:27 - loss: 1.100 - ETA: 2:25 - loss: 1.100 - ETA: 2:24 - loss: 1.100 - ETA: 2:22 - loss: 1.100 - ETA: 2:21 - loss: 1.100 - ETA: 2:19 - loss: 1.099 - ETA: 2:18 - loss: 1.100 - ETA: 2:16 - loss: 1.100 - ETA: 2:14 - loss: 1.100 - ETA: 2:13 - loss: 1.099 - ETA: 2:11 - loss: 1.099 - ETA: 2:10 - loss: 1.097 - ETA: 2:08 - loss: 1.096 - ETA: 2:07 - loss: 1.094 - ETA: 2:05 - loss: 1.096 - ETA: 2:04 - loss: 1.095 - ETA: 2:02 - loss: 1.095 - ETA: 2:00 - loss: 1.095 - ETA: 1:59 - loss: 1.094 - ETA: 1:57 - loss: 1.094 - ETA: 1:56 - loss: 1.094 - ETA: 1:54 - loss: 1.095 - ETA: 1:53 - loss: 1.094 - ETA: 1:51 - loss: 1.094 - ETA: 1:50 - loss: 1.095 - ETA: 1:48 - loss: 1.096 - ETA: 1:46 - loss: 1.097 - ETA: 1:45 - loss: 1.096 - ETA: 1:43 - loss: 1.097 - ETA: 1:42 - loss: 1.097 - ETA: 1:40 - loss: 1.096 - ETA: 1:39 - loss: 1.096 - ETA: 1:37 - loss: 1.096 - ETA: 1:36 - loss: 1.097 - ETA: 1:34 - loss: 1.096 - ETA: 1:33 - loss: 1.095 - ETA: 1:31 - loss: 1.096 - ETA: 1:29 - loss: 1.096 - ETA: 1:28 - loss: 1.095 - ETA: 1:26 - loss: 1.096 - ETA: 1:25 - loss: 1.096 - ETA: 1:23 - loss: 1.098 - ETA: 1:22 - loss: 1.098 - ETA: 1:20 - loss: 1.099 - ETA: 1:19 - loss: 1.098 - ETA: 1:17 - loss: 1.098 - ETA: 1:15 - loss: 1.098 - ETA: 1:14 - loss: 1.096 - ETA: 1:12 - loss: 1.096 - ETA: 1:11 - loss: 1.096 - ETA: 1:09 - loss: 1.096 - ETA: 1:08 - loss: 1.096 - ETA: 1:06 - loss: 1.096 - ETA: 1:05 - loss: 1.096 - ETA: 1:03 - loss: 1.095 - ETA: 1:02 - loss: 1.095 - ETA: 1:00 - loss: 1.094 - ETA: 58s - loss: 1.094 - ETA: 57s - loss: 1.09 - ETA: 55s - loss: 1.09 - ETA: 54s - loss: 1.09 - ETA: 52s - loss: 1.09 - ETA: 51s - loss: 1.09 - ETA: 49s - loss: 1.09 - ETA: 48s - loss: 1.09 - ETA: 46s - loss: 1.09 - ETA: 45s - loss: 1.09 - ETA: 43s - loss: 1.09 - ETA: 41s - loss: 1.09 - ETA: 40s - loss: 1.09 - ETA: 38s - loss: 1.09 - ETA: 37s - loss: 1.09 - ETA: 35s - loss: 1.09 - ETA: 34s - loss: 1.09 - ETA: 32s - loss: 1.09 - ETA: 31s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 27s - loss: 1.09 - ETA: 26s - loss: 1.09 - ETA: 24s - loss: 1.09 - ETA: 23s - loss: 1.09 - ETA: 21s - loss: 1.09 - ETA: 20s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0940 - ETA: 7s - loss: 1.094 - ETA: 6s - loss: 1.094 - ETA: 4s - loss: 1.094 - ETA: 3s - loss: 1.093 - ETA: 1s - loss: 1.093 - 292s 2s/step - loss: 1.0923 - val_loss: 1.3623\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.36652 to 1.36232, saving model to ./model_files/weights/VGG16_LSTM_Flickr8k_2l_32b_bn_dr_attn_bahdanau.hdf5\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:50 - loss: 0.950 - ETA: 4:47 - loss: 1.026 - ETA: 4:46 - loss: 0.994 - ETA: 4:44 - loss: 1.028 - ETA: 4:43 - loss: 1.041 - ETA: 4:41 - loss: 1.036 - ETA: 4:39 - loss: 1.030 - ETA: 4:38 - loss: 1.051 - ETA: 4:37 - loss: 1.054 - ETA: 4:35 - loss: 1.049 - ETA: 4:33 - loss: 1.040 - ETA: 4:32 - loss: 1.050 - ETA: 4:30 - loss: 1.069 - ETA: 4:28 - loss: 1.071 - ETA: 4:27 - loss: 1.075 - ETA: 4:25 - loss: 1.080 - ETA: 4:24 - loss: 1.085 - ETA: 4:22 - loss: 1.094 - ETA: 4:21 - loss: 1.096 - ETA: 4:19 - loss: 1.107 - ETA: 4:17 - loss: 1.108 - ETA: 4:16 - loss: 1.104 - ETA: 4:14 - loss: 1.107 - ETA: 4:13 - loss: 1.105 - ETA: 4:11 - loss: 1.105 - ETA: 4:10 - loss: 1.112 - ETA: 4:08 - loss: 1.116 - ETA: 4:06 - loss: 1.118 - ETA: 4:05 - loss: 1.121 - ETA: 4:03 - loss: 1.113 - ETA: 4:02 - loss: 1.111 - ETA: 4:00 - loss: 1.112 - ETA: 3:59 - loss: 1.108 - ETA: 3:57 - loss: 1.104 - ETA: 3:56 - loss: 1.106 - ETA: 3:54 - loss: 1.104 - ETA: 3:52 - loss: 1.101 - ETA: 3:51 - loss: 1.102 - ETA: 3:49 - loss: 1.101 - ETA: 3:48 - loss: 1.100 - ETA: 3:46 - loss: 1.099 - ETA: 3:45 - loss: 1.096 - ETA: 3:43 - loss: 1.093 - ETA: 3:42 - loss: 1.092 - ETA: 3:40 - loss: 1.092 - ETA: 3:38 - loss: 1.091 - ETA: 3:37 - loss: 1.093 - ETA: 3:35 - loss: 1.089 - ETA: 3:34 - loss: 1.090 - ETA: 3:32 - loss: 1.090 - ETA: 3:31 - loss: 1.091 - ETA: 3:29 - loss: 1.090 - ETA: 3:28 - loss: 1.091 - ETA: 3:26 - loss: 1.092 - ETA: 3:25 - loss: 1.094 - ETA: 3:23 - loss: 1.094 - ETA: 3:22 - loss: 1.092 - ETA: 3:20 - loss: 1.091 - ETA: 3:18 - loss: 1.092 - ETA: 3:17 - loss: 1.092 - ETA: 3:15 - loss: 1.090 - ETA: 3:14 - loss: 1.090 - ETA: 3:12 - loss: 1.088 - ETA: 3:11 - loss: 1.085 - ETA: 3:09 - loss: 1.086 - ETA: 3:08 - loss: 1.084 - ETA: 3:06 - loss: 1.082 - ETA: 3:04 - loss: 1.079 - ETA: 3:03 - loss: 1.078 - ETA: 3:01 - loss: 1.079 - ETA: 3:00 - loss: 1.079 - ETA: 2:58 - loss: 1.077 - ETA: 2:57 - loss: 1.075 - ETA: 2:55 - loss: 1.074 - ETA: 2:54 - loss: 1.074 - ETA: 2:52 - loss: 1.072 - ETA: 2:50 - loss: 1.073 - ETA: 2:49 - loss: 1.073 - ETA: 2:47 - loss: 1.072 - ETA: 2:46 - loss: 1.070 - ETA: 2:44 - loss: 1.070 - ETA: 2:43 - loss: 1.073 - ETA: 2:41 - loss: 1.073 - ETA: 2:40 - loss: 1.075 - ETA: 2:38 - loss: 1.076 - ETA: 2:37 - loss: 1.076 - ETA: 2:35 - loss: 1.077 - ETA: 2:33 - loss: 1.077 - ETA: 2:32 - loss: 1.075 - ETA: 2:30 - loss: 1.076 - ETA: 2:29 - loss: 1.078 - ETA: 2:27 - loss: 1.078 - ETA: 2:26 - loss: 1.079 - ETA: 2:24 - loss: 1.079 - ETA: 2:23 - loss: 1.081 - ETA: 2:21 - loss: 1.081 - ETA: 2:19 - loss: 1.080 - ETA: 2:18 - loss: 1.080 - ETA: 2:16 - loss: 1.080 - ETA: 2:15 - loss: 1.080 - ETA: 2:13 - loss: 1.079 - ETA: 2:12 - loss: 1.078 - ETA: 2:10 - loss: 1.077 - ETA: 2:09 - loss: 1.075 - ETA: 2:07 - loss: 1.076 - ETA: 2:05 - loss: 1.077 - ETA: 2:04 - loss: 1.077 - ETA: 2:02 - loss: 1.075 - ETA: 2:01 - loss: 1.076 - ETA: 1:59 - loss: 1.075 - ETA: 1:58 - loss: 1.074 - ETA: 1:56 - loss: 1.073 - ETA: 1:55 - loss: 1.073 - ETA: 1:53 - loss: 1.075 - ETA: 1:51 - loss: 1.075 - ETA: 1:50 - loss: 1.074 - ETA: 1:48 - loss: 1.075 - ETA: 1:47 - loss: 1.075 - ETA: 1:45 - loss: 1.075 - ETA: 1:44 - loss: 1.074 - ETA: 1:42 - loss: 1.074 - ETA: 1:41 - loss: 1.074 - ETA: 2:10 - loss: 1.073 - ETA: 2:14 - loss: 1.074 - ETA: 2:12 - loss: 1.075 - ETA: 2:10 - loss: 1.074 - ETA: 2:08 - loss: 1.073 - ETA: 2:06 - loss: 1.072 - ETA: 2:04 - loss: 1.072 - ETA: 2:03 - loss: 1.072 - ETA: 2:00 - loss: 1.072 - ETA: 1:58 - loss: 1.071 - ETA: 1:56 - loss: 1.071 - ETA: 1:54 - loss: 1.071 - ETA: 1:51 - loss: 1.071 - ETA: 1:49 - loss: 1.071 - ETA: 1:47 - loss: 1.073 - ETA: 1:45 - loss: 1.072 - ETA: 1:42 - loss: 1.072 - ETA: 1:40 - loss: 1.071 - ETA: 1:38 - loss: 1.071 - ETA: 1:35 - loss: 1.070 - ETA: 1:33 - loss: 1.070 - ETA: 1:31 - loss: 1.071 - ETA: 1:29 - loss: 1.070 - ETA: 1:27 - loss: 1.070 - ETA: 1:24 - loss: 1.070 - ETA: 1:22 - loss: 1.070 - ETA: 1:20 - loss: 1.069 - ETA: 1:18 - loss: 1.069 - ETA: 1:15 - loss: 1.069 - ETA: 1:13 - loss: 1.069 - ETA: 1:11 - loss: 1.069 - ETA: 1:09 - loss: 1.069 - ETA: 1:07 - loss: 1.070 - ETA: 1:05 - loss: 1.070 - ETA: 1:02 - loss: 1.070 - ETA: 1:00 - loss: 1.068 - ETA: 58s - loss: 1.069 - ETA: 56s - loss: 1.07 - ETA: 54s - loss: 1.07 - ETA: 52s - loss: 1.07 - ETA: 49s - loss: 1.07 - ETA: 47s - loss: 1.07 - ETA: 45s - loss: 1.07 - ETA: 43s - loss: 1.07 - ETA: 41s - loss: 1.07 - ETA: 39s - loss: 1.07 - ETA: 37s - loss: 1.07 - ETA: 35s - loss: 1.07 - ETA: 33s - loss: 1.07 - ETA: 30s - loss: 1.06 - ETA: 28s - loss: 1.07 - ETA: 26s - loss: 1.07 - ETA: 24s - loss: 1.07 - ETA: 22s - loss: 1.07 - ETA: 20s - loss: 1.07 - ETA: 18s - loss: 1.07 - ETA: 16s - loss: 1.07 - ETA: 14s - loss: 1.07 - ETA: 12s - loss: 1.06 - ETA: 10s - loss: 1.07 - ETA: 8s - loss: 1.0711 - ETA: 6s - loss: 1.070 - ETA: 4s - loss: 1.070 - ETA: 2s - loss: 1.070 - 382s 2s/step - loss: 1.0710 - val_loss: 1.5531\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.36232\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 5:06 - loss: 1.304 - ETA: 5:05 - loss: 1.145 - ETA: 4:57 - loss: 1.081 - ETA: 4:53 - loss: 1.079 - ETA: 4:49 - loss: 1.096 - ETA: 4:46 - loss: 1.089 - ETA: 4:44 - loss: 1.081 - ETA: 4:42 - loss: 1.096 - ETA: 4:40 - loss: 1.095 - ETA: 4:38 - loss: 1.086 - ETA: 4:37 - loss: 1.089 - ETA: 4:35 - loss: 1.065 - ETA: 4:33 - loss: 1.068 - ETA: 4:31 - loss: 1.070 - ETA: 4:29 - loss: 1.074 - ETA: 4:27 - loss: 1.078 - ETA: 4:26 - loss: 1.079 - ETA: 4:24 - loss: 1.072 - ETA: 4:23 - loss: 1.065 - ETA: 4:21 - loss: 1.075 - ETA: 4:21 - loss: 1.079 - ETA: 4:21 - loss: 1.079 - ETA: 4:21 - loss: 1.082 - ETA: 4:20 - loss: 1.083 - ETA: 4:20 - loss: 1.082 - ETA: 4:19 - loss: 1.076 - ETA: 4:18 - loss: 1.072 - ETA: 4:17 - loss: 1.068 - ETA: 4:20 - loss: 1.067 - ETA: 4:26 - loss: 1.065 - ETA: 4:31 - loss: 1.065 - ETA: 4:36 - loss: 1.069 - ETA: 4:40 - loss: 1.066 - ETA: 4:43 - loss: 1.067 - ETA: 4:46 - loss: 1.067 - ETA: 4:48 - loss: 1.073 - ETA: 4:51 - loss: 1.070 - ETA: 4:53 - loss: 1.074 - ETA: 4:54 - loss: 1.075 - ETA: 4:54 - loss: 1.075 - ETA: 4:53 - loss: 1.073 - ETA: 4:52 - loss: 1.072 - ETA: 4:51 - loss: 1.070 - ETA: 4:51 - loss: 1.071 - ETA: 4:49 - loss: 1.072 - ETA: 4:47 - loss: 1.070 - ETA: 4:44 - loss: 1.065 - ETA: 4:42 - loss: 1.064 - ETA: 4:39 - loss: 1.061 - ETA: 4:37 - loss: 1.059 - ETA: 4:35 - loss: 1.063 - ETA: 4:32 - loss: 1.063 - ETA: 4:30 - loss: 1.060 - ETA: 4:27 - loss: 1.060 - ETA: 4:24 - loss: 1.058 - ETA: 4:21 - loss: 1.060 - ETA: 4:19 - loss: 1.060 - ETA: 4:16 - loss: 1.059 - ETA: 4:13 - loss: 1.058 - ETA: 4:11 - loss: 1.061 - ETA: 4:08 - loss: 1.057 - ETA: 4:06 - loss: 1.059 - ETA: 4:03 - loss: 1.057 - ETA: 4:00 - loss: 1.055 - ETA: 3:58 - loss: 1.055 - ETA: 3:56 - loss: 1.055 - ETA: 3:53 - loss: 1.054 - ETA: 3:51 - loss: 1.057 - ETA: 3:48 - loss: 1.056 - ETA: 3:46 - loss: 1.056 - ETA: 3:44 - loss: 1.059 - ETA: 3:41 - loss: 1.059 - ETA: 3:39 - loss: 1.059 - ETA: 3:36 - loss: 1.061 - ETA: 3:34 - loss: 1.061 - ETA: 3:32 - loss: 1.061 - ETA: 3:29 - loss: 1.059 - ETA: 3:27 - loss: 1.058 - ETA: 3:25 - loss: 1.058 - ETA: 3:23 - loss: 1.058 - ETA: 3:20 - loss: 1.058 - ETA: 3:18 - loss: 1.059 - ETA: 3:16 - loss: 1.058 - ETA: 3:13 - loss: 1.057 - ETA: 3:11 - loss: 1.057 - ETA: 3:09 - loss: 1.058 - ETA: 3:06 - loss: 1.058 - ETA: 3:04 - loss: 1.057 - ETA: 3:02 - loss: 1.056 - ETA: 3:00 - loss: 1.056 - ETA: 2:58 - loss: 1.056 - ETA: 2:56 - loss: 1.056 - ETA: 2:54 - loss: 1.057 - ETA: 2:52 - loss: 1.058 - ETA: 2:49 - loss: 1.059 - ETA: 2:47 - loss: 1.060 - ETA: 2:45 - loss: 1.059 - ETA: 2:43 - loss: 1.058 - ETA: 2:41 - loss: 1.057 - ETA: 2:39 - loss: 1.056 - ETA: 2:37 - loss: 1.055 - ETA: 2:35 - loss: 1.053 - ETA: 2:33 - loss: 1.054 - ETA: 2:31 - loss: 1.053 - ETA: 2:29 - loss: 1.052 - ETA: 2:28 - loss: 1.050 - ETA: 2:26 - loss: 1.051 - ETA: 2:24 - loss: 1.051 - ETA: 2:22 - loss: 1.049 - ETA: 2:20 - loss: 1.049 - ETA: 2:18 - loss: 1.049 - ETA: 2:16 - loss: 1.047 - ETA: 2:14 - loss: 1.046 - ETA: 2:12 - loss: 1.048 - ETA: 2:10 - loss: 1.048 - ETA: 2:08 - loss: 1.050 - ETA: 2:06 - loss: 1.049 - ETA: 2:04 - loss: 1.051 - ETA: 2:03 - loss: 1.050 - ETA: 2:01 - loss: 1.051 - ETA: 1:59 - loss: 1.052 - ETA: 1:57 - loss: 1.054 - ETA: 1:55 - loss: 1.054 - ETA: 1:53 - loss: 1.053 - ETA: 1:51 - loss: 1.053 - ETA: 1:49 - loss: 1.054 - ETA: 1:47 - loss: 1.054 - ETA: 1:45 - loss: 1.053 - ETA: 1:43 - loss: 1.053 - ETA: 1:41 - loss: 1.053 - ETA: 1:40 - loss: 1.053 - ETA: 1:38 - loss: 1.053 - ETA: 1:36 - loss: 1.052 - ETA: 1:34 - loss: 1.052 - ETA: 1:32 - loss: 1.052 - ETA: 1:30 - loss: 1.053 - ETA: 1:28 - loss: 1.052 - ETA: 1:26 - loss: 1.052 - ETA: 1:25 - loss: 1.051 - ETA: 1:23 - loss: 1.050 - ETA: 1:21 - loss: 1.049 - ETA: 1:19 - loss: 1.050 - ETA: 1:17 - loss: 1.050 - ETA: 1:15 - loss: 1.049 - ETA: 1:14 - loss: 1.049 - ETA: 1:12 - loss: 1.050 - ETA: 1:10 - loss: 1.049 - ETA: 1:08 - loss: 1.049 - ETA: 1:06 - loss: 1.050 - ETA: 1:05 - loss: 1.051 - ETA: 1:03 - loss: 1.051 - ETA: 1:01 - loss: 1.052 - ETA: 59s - loss: 1.051 - ETA: 57s - loss: 1.05 - ETA: 56s - loss: 1.05 - ETA: 54s - loss: 1.05 - ETA: 52s - loss: 1.05 - ETA: 50s - loss: 1.05 - ETA: 48s - loss: 1.05 - ETA: 47s - loss: 1.05 - ETA: 45s - loss: 1.05 - ETA: 43s - loss: 1.05 - ETA: 41s - loss: 1.05 - ETA: 40s - loss: 1.05 - ETA: 38s - loss: 1.05 - ETA: 36s - loss: 1.05 - ETA: 34s - loss: 1.05 - ETA: 32s - loss: 1.05 - ETA: 31s - loss: 1.05 - ETA: 29s - loss: 1.05 - ETA: 27s - loss: 1.05 - ETA: 25s - loss: 1.05 - ETA: 24s - loss: 1.05 - ETA: 22s - loss: 1.05 - ETA: 20s - loss: 1.05 - ETA: 18s - loss: 1.05 - ETA: 17s - loss: 1.05 - ETA: 15s - loss: 1.05 - ETA: 13s - loss: 1.05 - ETA: 12s - loss: 1.05 - ETA: 10s - loss: 1.05 - ETA: 8s - loss: 1.0512 - ETA: 6s - loss: 1.051 - ETA: 5s - loss: 1.050 - ETA: 3s - loss: 1.050 - ETA: 1s - loss: 1.050 - 323s 2s/step - loss: 1.0505 - val_loss: 1.4631\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.36232\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:48 - loss: 1.013 - ETA: 4:46 - loss: 1.073 - ETA: 4:45 - loss: 1.090 - ETA: 4:43 - loss: 1.108 - ETA: 4:42 - loss: 1.094 - ETA: 4:41 - loss: 1.052 - ETA: 4:39 - loss: 1.055 - ETA: 4:38 - loss: 1.041 - ETA: 4:36 - loss: 1.038 - ETA: 4:35 - loss: 1.057 - ETA: 4:33 - loss: 1.065 - ETA: 4:31 - loss: 1.069 - ETA: 4:30 - loss: 1.079 - ETA: 4:28 - loss: 1.077 - ETA: 4:27 - loss: 1.068 - ETA: 4:25 - loss: 1.066 - ETA: 4:24 - loss: 1.058 - ETA: 4:22 - loss: 1.061 - ETA: 4:20 - loss: 1.066 - ETA: 4:19 - loss: 1.057 - ETA: 4:17 - loss: 1.054 - ETA: 4:16 - loss: 1.060 - ETA: 4:14 - loss: 1.061 - ETA: 4:13 - loss: 1.056 - ETA: 4:11 - loss: 1.057 - ETA: 4:09 - loss: 1.051 - ETA: 4:08 - loss: 1.050 - ETA: 4:06 - loss: 1.044 - ETA: 4:05 - loss: 1.039 - ETA: 4:11 - loss: 1.039 - ETA: 4:19 - loss: 1.043 - ETA: 4:26 - loss: 1.041 - ETA: 4:33 - loss: 1.046 - ETA: 4:39 - loss: 1.049 - ETA: 4:45 - loss: 1.051 - ETA: 4:51 - loss: 1.049 - ETA: 4:55 - loss: 1.044 - ETA: 5:00 - loss: 1.048 - ETA: 5:04 - loss: 1.045 - ETA: 5:08 - loss: 1.044 - ETA: 5:12 - loss: 1.043 - ETA: 5:14 - loss: 1.042 - ETA: 5:14 - loss: 1.042 - ETA: 5:13 - loss: 1.041 - ETA: 5:12 - loss: 1.040 - ETA: 5:12 - loss: 1.041 - ETA: 5:11 - loss: 1.037 - ETA: 5:09 - loss: 1.036 - ETA: 5:06 - loss: 1.034 - ETA: 5:03 - loss: 1.038 - ETA: 5:00 - loss: 1.038 - ETA: 4:58 - loss: 1.038 - ETA: 4:55 - loss: 1.042 - ETA: 4:52 - loss: 1.042 - ETA: 4:50 - loss: 1.043 - ETA: 4:47 - loss: 1.045 - ETA: 4:44 - loss: 1.043 - ETA: 4:41 - loss: 1.044 - ETA: 4:38 - loss: 1.046 - ETA: 4:35 - loss: 1.046 - ETA: 4:32 - loss: 1.047 - ETA: 4:29 - loss: 1.046 - ETA: 4:26 - loss: 1.046 - ETA: 4:23 - loss: 1.045 - ETA: 4:20 - loss: 1.043 - ETA: 4:17 - loss: 1.043 - ETA: 4:14 - loss: 1.042 - ETA: 4:11 - loss: 1.040 - ETA: 4:08 - loss: 1.038 - ETA: 4:06 - loss: 1.037 - ETA: 4:03 - loss: 1.037 - ETA: 4:00 - loss: 1.036 - ETA: 3:57 - loss: 1.034 - ETA: 3:55 - loss: 1.034 - ETA: 3:52 - loss: 1.036 - ETA: 3:49 - loss: 1.036 - ETA: 3:47 - loss: 1.036 - ETA: 3:44 - loss: 1.037 - ETA: 3:41 - loss: 1.036 - ETA: 3:39 - loss: 1.036 - ETA: 3:36 - loss: 1.039 - ETA: 3:34 - loss: 1.037 - ETA: 3:31 - loss: 1.035 - ETA: 3:29 - loss: 1.034 - ETA: 3:26 - loss: 1.033 - ETA: 3:24 - loss: 1.031 - ETA: 3:21 - loss: 1.031 - ETA: 3:19 - loss: 1.031 - ETA: 3:16 - loss: 1.033 - ETA: 3:14 - loss: 1.032 - ETA: 3:12 - loss: 1.031 - ETA: 3:09 - loss: 1.032 - ETA: 3:07 - loss: 1.032 - ETA: 3:04 - loss: 1.031 - ETA: 3:02 - loss: 1.030 - ETA: 3:00 - loss: 1.029 - ETA: 2:57 - loss: 1.028 - ETA: 2:55 - loss: 1.028 - ETA: 2:53 - loss: 1.027 - ETA: 2:50 - loss: 1.028 - ETA: 2:48 - loss: 1.027 - ETA: 2:46 - loss: 1.028 - ETA: 2:44 - loss: 1.029 - ETA: 2:41 - loss: 1.029 - ETA: 2:39 - loss: 1.029 - ETA: 2:37 - loss: 1.029 - ETA: 2:35 - loss: 1.030 - ETA: 2:32 - loss: 1.031 - ETA: 2:30 - loss: 1.029 - ETA: 2:28 - loss: 1.030 - ETA: 2:26 - loss: 1.029 - ETA: 2:24 - loss: 1.030 - ETA: 2:22 - loss: 1.029 - ETA: 2:20 - loss: 1.029 - ETA: 2:18 - loss: 1.031 - ETA: 2:15 - loss: 1.032 - ETA: 2:13 - loss: 1.032 - ETA: 2:11 - loss: 1.031 - ETA: 2:09 - loss: 1.031 - ETA: 2:07 - loss: 1.031 - ETA: 2:05 - loss: 1.029 - ETA: 2:03 - loss: 1.029 - ETA: 2:01 - loss: 1.029 - ETA: 1:59 - loss: 1.029 - ETA: 1:57 - loss: 1.028 - ETA: 1:55 - loss: 1.030 - ETA: 1:53 - loss: 1.029 - ETA: 1:51 - loss: 1.029 - ETA: 1:49 - loss: 1.028 - ETA: 1:47 - loss: 1.027 - ETA: 1:45 - loss: 1.027 - ETA: 1:43 - loss: 1.027 - ETA: 1:41 - loss: 1.025 - ETA: 1:39 - loss: 1.025 - ETA: 1:37 - loss: 1.024 - ETA: 1:35 - loss: 1.024 - ETA: 1:33 - loss: 1.024 - ETA: 1:31 - loss: 1.024 - ETA: 1:29 - loss: 1.024 - ETA: 1:27 - loss: 1.023 - ETA: 1:25 - loss: 1.024 - ETA: 1:23 - loss: 1.024 - ETA: 1:21 - loss: 1.024 - ETA: 1:19 - loss: 1.023 - ETA: 1:17 - loss: 1.023 - ETA: 1:15 - loss: 1.023 - ETA: 1:13 - loss: 1.024 - ETA: 1:11 - loss: 1.024 - ETA: 1:10 - loss: 1.024 - ETA: 1:08 - loss: 1.023 - ETA: 1:06 - loss: 1.023 - ETA: 1:04 - loss: 1.022 - ETA: 1:02 - loss: 1.023 - ETA: 1:00 - loss: 1.022 - ETA: 58s - loss: 1.021 - ETA: 56s - loss: 1.02 - ETA: 54s - loss: 1.02 - ETA: 52s - loss: 1.02 - ETA: 51s - loss: 1.02 - ETA: 49s - loss: 1.02 - ETA: 47s - loss: 1.02 - ETA: 45s - loss: 1.02 - ETA: 43s - loss: 1.02 - ETA: 41s - loss: 1.02 - ETA: 39s - loss: 1.02 - ETA: 38s - loss: 1.02 - ETA: 36s - loss: 1.02 - ETA: 34s - loss: 1.02 - ETA: 32s - loss: 1.02 - ETA: 30s - loss: 1.02 - ETA: 28s - loss: 1.02 - ETA: 27s - loss: 1.02 - ETA: 25s - loss: 1.02 - ETA: 23s - loss: 1.02 - ETA: 21s - loss: 1.02 - ETA: 19s - loss: 1.02 - ETA: 17s - loss: 1.02 - ETA: 16s - loss: 1.02 - ETA: 14s - loss: 1.02 - ETA: 12s - loss: 1.02 - ETA: 10s - loss: 1.02 - ETA: 8s - loss: 1.0202 - ETA: 7s - loss: 1.019 - ETA: 5s - loss: 1.020 - ETA: 3s - loss: 1.020 - ETA: 1s - loss: 1.021 - 336s 2s/step - loss: 1.0211 - val_loss: 1.3020\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.36232 to 1.30204, saving model to ./model_files/weights/VGG16_LSTM_Flickr8k_2l_32b_bn_dr_attn_bahdanau.hdf5\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:47 - loss: 1.207 - ETA: 4:46 - loss: 1.087 - ETA: 4:45 - loss: 1.020 - ETA: 4:44 - loss: 1.047 - ETA: 4:42 - loss: 1.038 - ETA: 4:40 - loss: 1.032 - ETA: 4:39 - loss: 1.033 - ETA: 4:37 - loss: 1.019 - ETA: 4:36 - loss: 1.017 - ETA: 4:34 - loss: 1.024 - ETA: 4:33 - loss: 1.015 - ETA: 4:31 - loss: 1.009 - ETA: 4:29 - loss: 1.005 - ETA: 4:28 - loss: 1.012 - ETA: 4:26 - loss: 1.015 - ETA: 4:25 - loss: 1.013 - ETA: 4:23 - loss: 1.014 - ETA: 4:22 - loss: 1.009 - ETA: 4:20 - loss: 1.015 - ETA: 4:19 - loss: 1.011 - ETA: 4:17 - loss: 1.019 - ETA: 4:15 - loss: 1.014 - ETA: 4:14 - loss: 1.016 - ETA: 4:12 - loss: 1.016 - ETA: 4:11 - loss: 1.019 - ETA: 4:09 - loss: 1.017 - ETA: 4:08 - loss: 1.014 - ETA: 4:06 - loss: 1.005 - ETA: 4:05 - loss: 1.005 - ETA: 4:03 - loss: 1.002 - ETA: 4:01 - loss: 1.002 - ETA: 4:00 - loss: 0.998 - ETA: 3:58 - loss: 0.997 - ETA: 3:57 - loss: 0.994 - ETA: 3:55 - loss: 0.997 - ETA: 3:54 - loss: 0.997 - ETA: 3:52 - loss: 0.994 - ETA: 3:51 - loss: 1.001 - ETA: 3:49 - loss: 0.998 - ETA: 3:47 - loss: 0.993 - ETA: 3:46 - loss: 0.994 - ETA: 3:44 - loss: 0.993 - ETA: 3:43 - loss: 0.990 - ETA: 3:41 - loss: 0.992 - ETA: 3:40 - loss: 0.993 - ETA: 3:38 - loss: 0.990 - ETA: 3:37 - loss: 0.989 - ETA: 3:35 - loss: 0.989 - ETA: 3:33 - loss: 0.990 - ETA: 3:32 - loss: 0.992 - ETA: 3:30 - loss: 0.992 - ETA: 3:29 - loss: 0.995 - ETA: 3:27 - loss: 0.995 - ETA: 3:26 - loss: 0.995 - ETA: 3:24 - loss: 0.997 - ETA: 3:23 - loss: 0.996 - ETA: 3:21 - loss: 0.997 - ETA: 3:20 - loss: 0.995 - ETA: 3:18 - loss: 0.993 - ETA: 3:16 - loss: 0.994 - ETA: 3:15 - loss: 0.993 - ETA: 3:13 - loss: 0.993 - ETA: 3:12 - loss: 0.996 - ETA: 3:10 - loss: 0.997 - ETA: 3:09 - loss: 0.997 - ETA: 3:07 - loss: 0.995 - ETA: 3:06 - loss: 0.998 - ETA: 3:04 - loss: 0.997 - ETA: 3:02 - loss: 0.998 - ETA: 3:01 - loss: 0.997 - ETA: 2:59 - loss: 0.993 - ETA: 2:58 - loss: 0.995 - ETA: 2:56 - loss: 0.998 - ETA: 2:55 - loss: 0.997 - ETA: 2:53 - loss: 0.995 - ETA: 2:52 - loss: 0.996 - ETA: 2:50 - loss: 0.999 - ETA: 2:48 - loss: 0.998 - ETA: 2:47 - loss: 0.997 - ETA: 2:45 - loss: 0.998 - ETA: 2:44 - loss: 0.998 - ETA: 2:42 - loss: 0.998 - ETA: 2:41 - loss: 0.999 - ETA: 2:39 - loss: 1.000 - ETA: 2:38 - loss: 1.000 - ETA: 2:36 - loss: 0.999 - ETA: 2:35 - loss: 1.001 - ETA: 2:33 - loss: 1.001 - ETA: 2:31 - loss: 1.001 - ETA: 2:30 - loss: 1.001 - ETA: 2:28 - loss: 1.002 - ETA: 2:27 - loss: 1.000 - ETA: 2:25 - loss: 0.999 - ETA: 2:24 - loss: 0.998 - ETA: 2:22 - loss: 0.998 - ETA: 2:21 - loss: 0.999 - ETA: 2:19 - loss: 0.999 - ETA: 2:17 - loss: 0.998 - ETA: 2:16 - loss: 1.000 - ETA: 2:14 - loss: 1.000 - ETA: 2:13 - loss: 1.001 - ETA: 2:11 - loss: 1.000 - ETA: 2:10 - loss: 1.000 - ETA: 2:08 - loss: 1.000 - ETA: 2:07 - loss: 1.000 - ETA: 2:05 - loss: 1.000 - ETA: 2:04 - loss: 0.999 - ETA: 2:02 - loss: 0.999 - ETA: 2:00 - loss: 0.999 - ETA: 1:59 - loss: 0.999 - ETA: 1:57 - loss: 0.999 - ETA: 1:56 - loss: 0.999 - ETA: 1:54 - loss: 0.999 - ETA: 1:53 - loss: 0.999 - ETA: 1:51 - loss: 0.998 - ETA: 1:50 - loss: 0.996 - ETA: 1:48 - loss: 0.995 - ETA: 1:46 - loss: 0.995 - ETA: 1:45 - loss: 0.995 - ETA: 1:43 - loss: 0.996 - ETA: 1:42 - loss: 0.996 - ETA: 1:40 - loss: 0.995 - ETA: 1:39 - loss: 0.995 - ETA: 1:37 - loss: 0.995 - ETA: 1:36 - loss: 0.998 - ETA: 1:34 - loss: 0.998 - ETA: 1:33 - loss: 0.998 - ETA: 1:31 - loss: 1.000 - ETA: 1:29 - loss: 0.999 - ETA: 1:28 - loss: 1.000 - ETA: 1:26 - loss: 0.999 - ETA: 1:25 - loss: 0.998 - ETA: 1:23 - loss: 0.999 - ETA: 1:22 - loss: 0.998 - ETA: 1:20 - loss: 0.999 - ETA: 1:19 - loss: 1.000 - ETA: 1:17 - loss: 0.999 - ETA: 1:15 - loss: 0.999 - ETA: 1:14 - loss: 0.999 - ETA: 1:12 - loss: 0.998 - ETA: 1:11 - loss: 0.997 - ETA: 1:09 - loss: 0.996 - ETA: 1:08 - loss: 0.996 - ETA: 1:06 - loss: 0.997 - ETA: 1:05 - loss: 0.996 - ETA: 1:03 - loss: 0.996 - ETA: 1:02 - loss: 0.995 - ETA: 1:00 - loss: 0.994 - ETA: 58s - loss: 0.994 - ETA: 57s - loss: 0.99 - ETA: 55s - loss: 0.99 - ETA: 54s - loss: 0.99 - ETA: 52s - loss: 0.99 - ETA: 51s - loss: 0.99 - ETA: 49s - loss: 0.99 - ETA: 48s - loss: 0.99 - ETA: 46s - loss: 0.99 - ETA: 44s - loss: 0.99 - ETA: 43s - loss: 0.99 - ETA: 41s - loss: 0.99 - ETA: 40s - loss: 0.99 - ETA: 38s - loss: 0.99 - ETA: 37s - loss: 0.99 - ETA: 35s - loss: 0.99 - ETA: 34s - loss: 0.99 - ETA: 32s - loss: 0.99 - ETA: 31s - loss: 0.99 - ETA: 29s - loss: 0.99 - ETA: 27s - loss: 0.99 - ETA: 26s - loss: 0.99 - ETA: 24s - loss: 0.99 - ETA: 23s - loss: 0.99 - ETA: 21s - loss: 0.99 - ETA: 20s - loss: 0.99 - ETA: 18s - loss: 0.99 - ETA: 17s - loss: 0.99 - ETA: 15s - loss: 0.99 - ETA: 13s - loss: 0.99 - ETA: 12s - loss: 0.99 - ETA: 10s - loss: 0.99 - ETA: 9s - loss: 0.9908 - ETA: 7s - loss: 0.990 - ETA: 6s - loss: 0.990 - ETA: 4s - loss: 0.989 - ETA: 3s - loss: 0.989 - ETA: 1s - loss: 0.988 - 292s 2s/step - loss: 0.9899 - val_loss: 1.4431\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.30204\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:47 - loss: 1.013 - ETA: 4:46 - loss: 1.004 - ETA: 4:44 - loss: 0.990 - ETA: 4:43 - loss: 1.021 - ETA: 4:41 - loss: 1.026 - ETA: 4:40 - loss: 1.026 - ETA: 4:38 - loss: 1.045 - ETA: 4:37 - loss: 1.031 - ETA: 4:35 - loss: 1.027 - ETA: 4:34 - loss: 1.021 - ETA: 4:32 - loss: 1.018 - ETA: 4:31 - loss: 1.020 - ETA: 4:29 - loss: 1.019 - ETA: 4:27 - loss: 1.010 - ETA: 4:26 - loss: 1.005 - ETA: 4:24 - loss: 1.002 - ETA: 4:23 - loss: 0.993 - ETA: 4:21 - loss: 0.996 - ETA: 4:20 - loss: 0.988 - ETA: 4:18 - loss: 0.986 - ETA: 4:17 - loss: 0.984 - ETA: 4:15 - loss: 0.979 - ETA: 4:14 - loss: 0.986 - ETA: 4:12 - loss: 0.985 - ETA: 4:10 - loss: 0.983 - ETA: 4:09 - loss: 0.977 - ETA: 4:07 - loss: 0.978 - ETA: 4:06 - loss: 0.978 - ETA: 4:04 - loss: 0.976 - ETA: 4:03 - loss: 0.975 - ETA: 4:01 - loss: 0.981 - ETA: 4:00 - loss: 0.979 - ETA: 3:58 - loss: 0.977 - ETA: 3:57 - loss: 0.976 - ETA: 3:55 - loss: 0.976 - ETA: 3:53 - loss: 0.971 - ETA: 3:52 - loss: 0.967 - ETA: 3:50 - loss: 0.965 - ETA: 3:49 - loss: 0.965 - ETA: 3:47 - loss: 0.966 - ETA: 3:46 - loss: 0.965 - ETA: 3:44 - loss: 0.963 - ETA: 3:43 - loss: 0.965 - ETA: 3:41 - loss: 0.966 - ETA: 3:40 - loss: 0.964 - ETA: 3:38 - loss: 0.962 - ETA: 3:36 - loss: 0.962 - ETA: 3:35 - loss: 0.961 - ETA: 3:33 - loss: 0.961 - ETA: 3:32 - loss: 0.963 - ETA: 3:30 - loss: 0.961 - ETA: 3:29 - loss: 0.964 - ETA: 3:27 - loss: 0.965 - ETA: 3:26 - loss: 0.962 - ETA: 3:24 - loss: 0.962 - ETA: 3:22 - loss: 0.959 - ETA: 3:21 - loss: 0.959 - ETA: 3:19 - loss: 0.963 - ETA: 3:18 - loss: 0.960 - ETA: 3:16 - loss: 0.962 - ETA: 3:15 - loss: 0.961 - ETA: 3:13 - loss: 0.961 - ETA: 3:12 - loss: 0.962 - ETA: 3:10 - loss: 0.964 - ETA: 3:09 - loss: 0.963 - ETA: 3:07 - loss: 0.967 - ETA: 3:05 - loss: 0.968 - ETA: 3:04 - loss: 0.968 - ETA: 3:02 - loss: 0.970 - ETA: 3:01 - loss: 0.971 - ETA: 2:59 - loss: 0.972 - ETA: 2:58 - loss: 0.972 - ETA: 2:56 - loss: 0.974 - ETA: 2:55 - loss: 0.972 - ETA: 2:53 - loss: 0.970 - ETA: 2:52 - loss: 0.972 - ETA: 2:50 - loss: 0.971 - ETA: 2:48 - loss: 0.970 - ETA: 2:47 - loss: 0.970 - ETA: 2:45 - loss: 0.971 - ETA: 2:44 - loss: 0.972 - ETA: 2:42 - loss: 0.974 - ETA: 2:41 - loss: 0.974 - ETA: 2:39 - loss: 0.975 - ETA: 2:38 - loss: 0.976 - ETA: 2:36 - loss: 0.975 - ETA: 2:34 - loss: 0.976 - ETA: 2:33 - loss: 0.976 - ETA: 2:31 - loss: 0.976 - ETA: 2:30 - loss: 0.977 - ETA: 2:28 - loss: 0.977 - ETA: 2:27 - loss: 0.977 - ETA: 2:25 - loss: 0.977 - ETA: 2:24 - loss: 0.976 - ETA: 2:22 - loss: 0.975 - ETA: 2:21 - loss: 0.976 - ETA: 2:19 - loss: 0.976 - ETA: 2:17 - loss: 0.976 - ETA: 2:16 - loss: 0.976 - ETA: 2:14 - loss: 0.977 - ETA: 2:13 - loss: 0.977 - ETA: 2:11 - loss: 0.975 - ETA: 2:10 - loss: 0.976 - ETA: 2:08 - loss: 0.976 - ETA: 2:07 - loss: 0.977 - ETA: 2:05 - loss: 0.977 - ETA: 2:03 - loss: 0.978 - ETA: 2:02 - loss: 0.978 - ETA: 2:00 - loss: 0.978 - ETA: 1:59 - loss: 0.977 - ETA: 1:57 - loss: 0.979 - ETA: 1:56 - loss: 0.979 - ETA: 1:54 - loss: 0.979 - ETA: 1:53 - loss: 0.979 - ETA: 1:51 - loss: 0.980 - ETA: 1:50 - loss: 0.979 - ETA: 1:48 - loss: 0.977 - ETA: 1:46 - loss: 0.977 - ETA: 1:45 - loss: 0.978 - ETA: 1:43 - loss: 0.978 - ETA: 1:42 - loss: 0.978 - ETA: 1:40 - loss: 0.978 - ETA: 1:39 - loss: 0.978 - ETA: 2:00 - loss: 0.978 - ETA: 2:02 - loss: 0.978 - ETA: 2:02 - loss: 0.978 - ETA: 2:00 - loss: 0.979 - ETA: 1:59 - loss: 0.979 - ETA: 1:57 - loss: 0.979 - ETA: 1:56 - loss: 0.978 - ETA: 1:54 - loss: 0.978 - ETA: 1:52 - loss: 0.979 - ETA: 1:50 - loss: 0.979 - ETA: 1:48 - loss: 0.980 - ETA: 1:46 - loss: 0.979 - ETA: 1:44 - loss: 0.980 - ETA: 1:42 - loss: 0.980 - ETA: 1:40 - loss: 0.979 - ETA: 1:38 - loss: 0.980 - ETA: 1:36 - loss: 0.979 - ETA: 1:33 - loss: 0.980 - ETA: 1:31 - loss: 0.979 - ETA: 1:29 - loss: 0.978 - ETA: 1:27 - loss: 0.978 - ETA: 1:25 - loss: 0.978 - ETA: 1:23 - loss: 0.979 - ETA: 1:21 - loss: 0.979 - ETA: 1:19 - loss: 0.980 - ETA: 1:17 - loss: 0.980 - ETA: 1:14 - loss: 0.980 - ETA: 1:12 - loss: 0.980 - ETA: 1:10 - loss: 0.980 - ETA: 1:08 - loss: 0.980 - ETA: 1:06 - loss: 0.980 - ETA: 1:04 - loss: 0.980 - ETA: 1:02 - loss: 0.980 - ETA: 1:00 - loss: 0.980 - ETA: 58s - loss: 0.980 - ETA: 56s - loss: 0.98 - ETA: 54s - loss: 0.98 - ETA: 52s - loss: 0.97 - ETA: 50s - loss: 0.98 - ETA: 47s - loss: 0.98 - ETA: 45s - loss: 0.97 - ETA: 43s - loss: 0.98 - ETA: 41s - loss: 0.98 - ETA: 39s - loss: 0.98 - ETA: 37s - loss: 0.98 - ETA: 35s - loss: 0.98 - ETA: 33s - loss: 0.98 - ETA: 31s - loss: 0.98 - ETA: 29s - loss: 0.98 - ETA: 27s - loss: 0.98 - ETA: 25s - loss: 0.98 - ETA: 23s - loss: 0.98 - ETA: 21s - loss: 0.98 - ETA: 19s - loss: 0.98 - ETA: 17s - loss: 0.98 - ETA: 15s - loss: 0.98 - ETA: 13s - loss: 0.98 - ETA: 11s - loss: 0.98 - ETA: 9s - loss: 0.9822 - ETA: 7s - loss: 0.981 - ETA: 5s - loss: 0.981 - ETA: 3s - loss: 0.981 - ETA: 1s - loss: 0.981 - 368s 2s/step - loss: 0.9820 - val_loss: 1.3528\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.30204\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 5:01 - loss: 0.927 - ETA: 4:59 - loss: 1.013 - ETA: 4:54 - loss: 1.015 - ETA: 4:50 - loss: 1.036 - ETA: 4:47 - loss: 1.030 - ETA: 4:45 - loss: 1.022 - ETA: 4:43 - loss: 0.995 - ETA: 4:41 - loss: 0.988 - ETA: 4:39 - loss: 0.982 - ETA: 4:37 - loss: 0.978 - ETA: 4:35 - loss: 0.991 - ETA: 4:33 - loss: 0.998 - ETA: 4:31 - loss: 0.993 - ETA: 4:30 - loss: 0.993 - ETA: 4:28 - loss: 1.000 - ETA: 4:26 - loss: 1.006 - ETA: 4:25 - loss: 1.002 - ETA: 4:23 - loss: 1.002 - ETA: 4:21 - loss: 0.997 - ETA: 4:20 - loss: 0.996 - ETA: 4:18 - loss: 0.996 - ETA: 4:16 - loss: 1.002 - ETA: 4:15 - loss: 0.995 - ETA: 4:13 - loss: 1.001 - ETA: 4:12 - loss: 0.999 - ETA: 4:10 - loss: 0.997 - ETA: 4:09 - loss: 1.000 - ETA: 4:07 - loss: 0.994 - ETA: 4:05 - loss: 0.991 - ETA: 4:04 - loss: 0.993 - ETA: 4:02 - loss: 0.989 - ETA: 4:01 - loss: 0.988 - ETA: 3:59 - loss: 0.986 - ETA: 3:57 - loss: 0.983 - ETA: 3:56 - loss: 0.987 - ETA: 3:54 - loss: 0.985 - ETA: 3:53 - loss: 0.980 - ETA: 3:51 - loss: 0.977 - ETA: 3:50 - loss: 0.977 - ETA: 3:48 - loss: 0.976 - ETA: 3:46 - loss: 0.974 - ETA: 3:45 - loss: 0.973 - ETA: 3:43 - loss: 0.973 - ETA: 3:42 - loss: 0.972 - ETA: 3:40 - loss: 0.975 - ETA: 3:39 - loss: 0.976 - ETA: 3:37 - loss: 0.976 - ETA: 3:35 - loss: 0.972 - ETA: 3:34 - loss: 0.969 - ETA: 3:32 - loss: 0.969 - ETA: 3:31 - loss: 0.969 - ETA: 3:29 - loss: 0.969 - ETA: 3:28 - loss: 0.969 - ETA: 3:26 - loss: 0.969 - ETA: 3:24 - loss: 0.968 - ETA: 3:23 - loss: 0.968 - ETA: 3:21 - loss: 0.972 - ETA: 3:20 - loss: 0.975 - ETA: 3:18 - loss: 0.977 - ETA: 3:17 - loss: 0.977 - ETA: 3:15 - loss: 0.977 - ETA: 3:14 - loss: 0.977 - ETA: 3:12 - loss: 0.975 - ETA: 3:10 - loss: 0.974 - ETA: 3:09 - loss: 0.975 - ETA: 3:07 - loss: 0.973 - ETA: 3:06 - loss: 0.972 - ETA: 3:04 - loss: 0.975 - ETA: 3:03 - loss: 0.975 - ETA: 3:01 - loss: 0.975 - ETA: 3:00 - loss: 0.974 - ETA: 2:58 - loss: 0.973 - ETA: 2:56 - loss: 0.972 - ETA: 2:55 - loss: 0.971 - ETA: 2:53 - loss: 0.973 - ETA: 2:52 - loss: 0.971 - ETA: 2:50 - loss: 0.972 - ETA: 2:49 - loss: 0.970 - ETA: 2:47 - loss: 0.971 - ETA: 2:46 - loss: 0.974 - ETA: 2:44 - loss: 0.975 - ETA: 2:42 - loss: 0.977 - ETA: 2:41 - loss: 0.975 - ETA: 2:39 - loss: 0.975 - ETA: 2:38 - loss: 0.977 - ETA: 2:36 - loss: 0.976 - ETA: 2:35 - loss: 0.976 - ETA: 2:33 - loss: 0.976 - ETA: 2:32 - loss: 0.977 - ETA: 2:30 - loss: 0.976 - ETA: 2:29 - loss: 0.976 - ETA: 2:27 - loss: 0.975 - ETA: 2:25 - loss: 0.975 - ETA: 2:24 - loss: 0.976 - ETA: 2:22 - loss: 0.974 - ETA: 2:21 - loss: 0.975 - ETA: 2:19 - loss: 0.975 - ETA: 2:18 - loss: 0.973 - ETA: 2:16 - loss: 0.972 - ETA: 2:15 - loss: 0.974 - ETA: 2:13 - loss: 0.974 - ETA: 2:11 - loss: 0.974 - ETA: 2:10 - loss: 0.974 - ETA: 2:08 - loss: 0.974 - ETA: 2:07 - loss: 0.975 - ETA: 2:05 - loss: 0.975 - ETA: 2:04 - loss: 0.974 - ETA: 2:02 - loss: 0.975 - ETA: 2:01 - loss: 0.974 - ETA: 1:59 - loss: 0.975 - ETA: 1:57 - loss: 0.974 - ETA: 1:56 - loss: 0.974 - ETA: 1:54 - loss: 0.974 - ETA: 1:53 - loss: 0.974 - ETA: 1:51 - loss: 0.974 - ETA: 1:50 - loss: 0.973 - ETA: 1:48 - loss: 0.972 - ETA: 1:47 - loss: 0.972 - ETA: 1:45 - loss: 0.972 - ETA: 1:43 - loss: 0.972 - ETA: 1:42 - loss: 0.972 - ETA: 1:40 - loss: 0.972 - ETA: 1:39 - loss: 0.972 - ETA: 1:37 - loss: 0.972 - ETA: 1:36 - loss: 0.973 - ETA: 1:34 - loss: 0.973 - ETA: 1:33 - loss: 0.974 - ETA: 1:31 - loss: 0.974 - ETA: 1:29 - loss: 0.973 - ETA: 1:28 - loss: 0.973 - ETA: 1:26 - loss: 0.974 - ETA: 1:25 - loss: 0.975 - ETA: 1:23 - loss: 0.975 - ETA: 1:22 - loss: 0.975 - ETA: 1:20 - loss: 0.975 - ETA: 1:19 - loss: 0.975 - ETA: 1:17 - loss: 0.975 - ETA: 1:16 - loss: 0.975 - ETA: 1:14 - loss: 0.975 - ETA: 1:12 - loss: 0.976 - ETA: 1:11 - loss: 0.976 - ETA: 1:09 - loss: 0.977 - ETA: 1:08 - loss: 0.978 - ETA: 1:06 - loss: 0.978 - ETA: 1:05 - loss: 0.977 - ETA: 1:03 - loss: 0.977 - ETA: 1:02 - loss: 0.977 - ETA: 1:00 - loss: 0.977 - ETA: 58s - loss: 0.977 - ETA: 57s - loss: 0.97 - ETA: 55s - loss: 0.97 - ETA: 54s - loss: 0.97 - ETA: 52s - loss: 0.97 - ETA: 51s - loss: 0.97 - ETA: 49s - loss: 0.97 - ETA: 48s - loss: 0.97 - ETA: 46s - loss: 0.97 - ETA: 44s - loss: 0.97 - ETA: 43s - loss: 0.97 - ETA: 41s - loss: 0.97 - ETA: 40s - loss: 0.97 - ETA: 38s - loss: 0.97 - ETA: 37s - loss: 0.97 - ETA: 35s - loss: 0.97 - ETA: 34s - loss: 0.97 - ETA: 32s - loss: 0.97 - ETA: 31s - loss: 0.97 - ETA: 29s - loss: 0.97 - ETA: 27s - loss: 0.97 - ETA: 26s - loss: 0.97 - ETA: 24s - loss: 0.97 - ETA: 23s - loss: 0.97 - ETA: 21s - loss: 0.97 - ETA: 20s - loss: 0.96 - ETA: 18s - loss: 0.97 - ETA: 17s - loss: 0.97 - ETA: 15s - loss: 0.97 - ETA: 13s - loss: 0.97 - ETA: 12s - loss: 0.97 - ETA: 10s - loss: 0.97 - ETA: 9s - loss: 0.9702 - ETA: 7s - loss: 0.970 - ETA: 6s - loss: 0.970 - ETA: 4s - loss: 0.969 - ETA: 3s - loss: 0.970 - ETA: 1s - loss: 0.970 - 292s 2s/step - loss: 0.9697 - val_loss: 1.3254\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.30204\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:49 - loss: 1.192 - ETA: 4:46 - loss: 1.060 - ETA: 4:45 - loss: 1.051 - ETA: 4:43 - loss: 1.072 - ETA: 4:42 - loss: 1.042 - ETA: 4:40 - loss: 1.009 - ETA: 4:39 - loss: 1.011 - ETA: 4:37 - loss: 0.997 - ETA: 4:36 - loss: 0.992 - ETA: 4:34 - loss: 0.999 - ETA: 4:32 - loss: 0.990 - ETA: 4:41 - loss: 0.987 - ETA: 15:37 - loss: 0.98 - ETA: 17:03 - loss: 0.98 - ETA: 16:47 - loss: 0.97 - ETA: 16:32 - loss: 0.97 - ETA: 15:51 - loss: 0.97 - ETA: 15:12 - loss: 0.97 - ETA: 14:38 - loss: 0.97 - ETA: 14:06 - loss: 0.97 - ETA: 13:38 - loss: 0.96 - ETA: 13:12 - loss: 0.97 - ETA: 12:48 - loss: 0.96 - ETA: 12:24 - loss: 0.96 - ETA: 12:01 - loss: 0.96 - ETA: 11:40 - loss: 0.98 - ETA: 11:20 - loss: 0.98 - ETA: 11:01 - loss: 0.98 - ETA: 10:44 - loss: 0.98 - ETA: 10:28 - loss: 0.98 - ETA: 10:12 - loss: 0.98 - ETA: 9:58 - loss: 0.9828 - ETA: 9:44 - loss: 0.984 - ETA: 9:31 - loss: 0.980 - ETA: 9:18 - loss: 0.978 - ETA: 9:06 - loss: 0.973 - ETA: 8:55 - loss: 0.968 - ETA: 8:44 - loss: 0.973 - ETA: 8:34 - loss: 0.970 - ETA: 8:24 - loss: 0.965 - ETA: 8:15 - loss: 0.967 - ETA: 8:05 - loss: 0.968 - ETA: 7:56 - loss: 0.965 - ETA: 7:48 - loss: 0.964 - ETA: 7:39 - loss: 0.967 - ETA: 7:31 - loss: 0.964 - ETA: 7:23 - loss: 0.963 - ETA: 7:16 - loss: 0.962 - ETA: 7:08 - loss: 0.961 - ETA: 7:01 - loss: 0.961 - ETA: 6:54 - loss: 0.960 - ETA: 6:47 - loss: 0.958 - ETA: 6:40 - loss: 0.961 - ETA: 6:34 - loss: 0.960 - ETA: 6:27 - loss: 0.964 - ETA: 6:21 - loss: 0.964 - ETA: 6:15 - loss: 0.965 - ETA: 6:09 - loss: 0.965 - ETA: 6:04 - loss: 0.966 - ETA: 5:58 - loss: 0.968 - ETA: 5:53 - loss: 0.968 - ETA: 5:48 - loss: 0.967 - ETA: 5:43 - loss: 0.967 - ETA: 5:38 - loss: 0.967 - ETA: 5:33 - loss: 0.968 - ETA: 5:29 - loss: 0.968 - ETA: 5:24 - loss: 0.970 - ETA: 5:19 - loss: 0.972 - ETA: 5:15 - loss: 0.971 - ETA: 5:11 - loss: 0.972 - ETA: 5:06 - loss: 0.971 - ETA: 5:02 - loss: 0.974 - ETA: 4:58 - loss: 0.973 - ETA: 4:54 - loss: 0.973 - ETA: 4:50 - loss: 0.974 - ETA: 4:46 - loss: 0.974 - ETA: 4:42 - loss: 0.973 - ETA: 4:38 - loss: 0.974 - ETA: 4:34 - loss: 0.974 - ETA: 4:31 - loss: 0.974 - ETA: 4:27 - loss: 0.975 - ETA: 4:23 - loss: 0.976 - ETA: 4:20 - loss: 0.977 - ETA: 4:16 - loss: 0.975 - ETA: 4:13 - loss: 0.973 - ETA: 4:09 - loss: 0.971 - ETA: 4:06 - loss: 0.974 - ETA: 4:02 - loss: 0.975 - ETA: 3:59 - loss: 0.975 - ETA: 3:55 - loss: 0.977 - ETA: 3:52 - loss: 0.976 - ETA: 3:49 - loss: 0.977 - ETA: 3:45 - loss: 0.975 - ETA: 3:42 - loss: 0.974 - ETA: 3:39 - loss: 0.974 - ETA: 3:36 - loss: 0.974 - ETA: 3:33 - loss: 0.974 - ETA: 3:30 - loss: 0.973 - ETA: 3:26 - loss: 0.972 - ETA: 3:23 - loss: 0.972 - ETA: 3:20 - loss: 0.973 - ETA: 3:17 - loss: 0.972 - ETA: 3:14 - loss: 0.972 - ETA: 3:11 - loss: 0.970 - ETA: 3:09 - loss: 0.969 - ETA: 3:06 - loss: 0.969 - ETA: 3:03 - loss: 0.970 - ETA: 3:00 - loss: 0.970 - ETA: 2:57 - loss: 0.970 - ETA: 2:54 - loss: 0.970 - ETA: 2:52 - loss: 0.970 - ETA: 2:49 - loss: 0.970 - ETA: 2:46 - loss: 0.970 - ETA: 2:43 - loss: 0.970 - ETA: 2:41 - loss: 0.970 - ETA: 2:38 - loss: 0.971 - ETA: 2:35 - loss: 0.970 - ETA: 2:33 - loss: 0.969 - ETA: 2:30 - loss: 0.969 - ETA: 2:28 - loss: 0.969 - ETA: 2:25 - loss: 0.968 - ETA: 2:23 - loss: 0.969 - ETA: 2:20 - loss: 0.968 - ETA: 2:17 - loss: 0.968 - ETA: 2:15 - loss: 0.968 - ETA: 2:12 - loss: 0.969 - ETA: 2:10 - loss: 0.970 - ETA: 2:08 - loss: 0.969 - ETA: 2:05 - loss: 0.969 - ETA: 2:03 - loss: 0.968 - ETA: 2:00 - loss: 0.968 - ETA: 1:58 - loss: 0.969 - ETA: 1:55 - loss: 0.968 - ETA: 1:53 - loss: 0.968 - ETA: 1:51 - loss: 0.968 - ETA: 1:48 - loss: 0.967 - ETA: 1:46 - loss: 0.968 - ETA: 1:44 - loss: 0.968 - ETA: 1:41 - loss: 0.967 - ETA: 1:39 - loss: 0.967 - ETA: 1:37 - loss: 0.967 - ETA: 1:34 - loss: 0.966 - ETA: 1:32 - loss: 0.966 - ETA: 1:30 - loss: 0.966 - ETA: 1:28 - loss: 0.966 - ETA: 1:25 - loss: 0.964 - ETA: 1:23 - loss: 0.964 - ETA: 1:21 - loss: 0.964 - ETA: 1:19 - loss: 0.965 - ETA: 1:16 - loss: 0.964 - ETA: 1:14 - loss: 0.964 - ETA: 1:12 - loss: 0.964 - ETA: 1:10 - loss: 0.964 - ETA: 1:08 - loss: 0.963 - ETA: 1:05 - loss: 0.962 - ETA: 1:03 - loss: 0.962 - ETA: 1:01 - loss: 0.961 - ETA: 59s - loss: 0.962 - ETA: 57s - loss: 0.96 - ETA: 55s - loss: 0.96 - ETA: 53s - loss: 0.96 - ETA: 50s - loss: 0.96 - ETA: 48s - loss: 0.96 - ETA: 46s - loss: 0.96 - ETA: 44s - loss: 0.96 - ETA: 42s - loss: 0.96 - ETA: 40s - loss: 0.96 - ETA: 38s - loss: 0.96 - ETA: 36s - loss: 0.96 - ETA: 34s - loss: 0.96 - ETA: 32s - loss: 0.96 - ETA: 30s - loss: 0.96 - ETA: 28s - loss: 0.96 - ETA: 26s - loss: 0.96 - ETA: 24s - loss: 0.96 - ETA: 22s - loss: 0.96 - ETA: 19s - loss: 0.96 - ETA: 17s - loss: 0.96 - ETA: 15s - loss: 0.96 - ETA: 13s - loss: 0.96 - ETA: 11s - loss: 0.96 - ETA: 9s - loss: 0.9652 - ETA: 7s - loss: 0.965 - ETA: 5s - loss: 0.965 - ETA: 3s - loss: 0.965 - ETA: 1s - loss: 0.964 - 371s 2s/step - loss: 0.9651 - val_loss: 1.2737\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.30204 to 1.27371, saving model to ./model_files/weights/VGG16_LSTM_Flickr8k_2l_32b_bn_dr_attn_bahdanau.hdf5\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - ETA: 4:47 - loss: 0.945 - ETA: 4:47 - loss: 0.937 - ETA: 4:45 - loss: 0.931 - ETA: 4:43 - loss: 0.967 - ETA: 4:42 - loss: 0.995 - ETA: 4:40 - loss: 1.017 - ETA: 4:39 - loss: 1.031 - ETA: 4:37 - loss: 1.043 - ETA: 4:35 - loss: 1.035 - ETA: 4:34 - loss: 1.024 - ETA: 4:32 - loss: 1.033 - ETA: 4:31 - loss: 1.014 - ETA: 4:29 - loss: 1.009 - ETA: 4:27 - loss: 1.011 - ETA: 4:26 - loss: 1.008 - ETA: 4:24 - loss: 1.012 - ETA: 4:23 - loss: 1.009 - ETA: 4:21 - loss: 0.996 - ETA: 4:20 - loss: 0.995 - ETA: 4:18 - loss: 0.993 - ETA: 4:17 - loss: 0.990 - ETA: 4:15 - loss: 0.991 - ETA: 4:14 - loss: 0.989 - ETA: 4:12 - loss: 0.989 - ETA: 4:10 - loss: 0.989 - ETA: 4:09 - loss: 0.991 - ETA: 4:07 - loss: 0.985 - ETA: 4:06 - loss: 0.979 - ETA: 4:04 - loss: 0.981 - ETA: 4:03 - loss: 0.981 - ETA: 4:01 - loss: 0.979 - ETA: 4:00 - loss: 0.979 - ETA: 3:58 - loss: 0.971 - ETA: 3:57 - loss: 0.969 - ETA: 3:55 - loss: 0.973 - ETA: 3:53 - loss: 0.973 - ETA: 3:52 - loss: 0.966 - ETA: 3:50 - loss: 0.970 - ETA: 3:49 - loss: 0.971 - ETA: 3:47 - loss: 0.970 - ETA: 3:46 - loss: 0.967 - ETA: 3:44 - loss: 0.967 - ETA: 3:43 - loss: 0.968 - ETA: 3:41 - loss: 0.966 - ETA: 3:40 - loss: 0.968 - ETA: 3:38 - loss: 0.968 - ETA: 3:36 - loss: 0.966 - ETA: 3:35 - loss: 0.965 - ETA: 3:33 - loss: 0.964 - ETA: 3:32 - loss: 0.962 - ETA: 3:30 - loss: 0.961 - ETA: 3:29 - loss: 0.959 - ETA: 3:27 - loss: 0.958 - ETA: 3:26 - loss: 0.957 - ETA: 3:24 - loss: 0.959 - ETA: 3:22 - loss: 0.959 - ETA: 3:21 - loss: 0.962 - ETA: 3:19 - loss: 0.960 - ETA: 3:18 - loss: 0.959 - ETA: 3:16 - loss: 0.958 - ETA: 3:15 - loss: 0.957 - ETA: 3:13 - loss: 0.957 - ETA: 3:12 - loss: 0.956 - ETA: 3:10 - loss: 0.958 - ETA: 3:09 - loss: 0.958 - ETA: 3:07 - loss: 0.958 - ETA: 3:06 - loss: 0.958 - ETA: 4:25 - loss: 0.957 - ETA: 4:41 - loss: 0.956 - ETA: 4:39 - loss: 0.957 - ETA: 4:37 - loss: 0.957 - ETA: 4:35 - loss: 0.956 - ETA: 4:33 - loss: 0.959 - ETA: 4:31 - loss: 0.958 - ETA: 4:29 - loss: 0.959 - ETA: 4:25 - loss: 0.960 - ETA: 4:22 - loss: 0.959 - ETA: 4:19 - loss: 0.959 - ETA: 4:16 - loss: 0.959 - ETA: 4:13 - loss: 0.959 - ETA: 4:10 - loss: 0.959 - ETA: 4:07 - loss: 0.959 - ETA: 4:04 - loss: 0.959 - ETA: 4:01 - loss: 0.959 - ETA: 3:58 - loss: 0.960 - ETA: 3:55 - loss: 0.960 - ETA: 3:52 - loss: 0.959 - ETA: 3:49 - loss: 0.958 - ETA: 3:46 - loss: 0.957 - ETA: 3:43 - loss: 0.956 - ETA: 3:40 - loss: 0.955 - ETA: 3:37 - loss: 0.956 - ETA: 3:34 - loss: 0.955 - ETA: 3:31 - loss: 0.956 - ETA: 3:28 - loss: 0.957 - ETA: 3:25 - loss: 0.957 - ETA: 3:22 - loss: 0.957 - ETA: 3:20 - loss: 0.959 - ETA: 3:17 - loss: 0.957 - ETA: 3:14 - loss: 0.955 - ETA: 3:11 - loss: 0.956 - ETA: 3:09 - loss: 0.956 - ETA: 3:06 - loss: 0.958 - ETA: 3:03 - loss: 0.957 - ETA: 3:01 - loss: 0.959 - ETA: 2:58 - loss: 0.957 - ETA: 2:55 - loss: 0.958 - ETA: 2:53 - loss: 0.956 - ETA: 2:50 - loss: 0.955 - ETA: 2:48 - loss: 0.956 - ETA: 2:45 - loss: 0.956 - ETA: 2:43 - loss: 0.956 - ETA: 2:40 - loss: 0.956 - ETA: 2:37 - loss: 0.955 - ETA: 2:35 - loss: 0.953 - ETA: 2:32 - loss: 0.953 - ETA: 2:30 - loss: 0.954 - ETA: 2:28 - loss: 0.953 - ETA: 2:25 - loss: 0.953 - ETA: 2:23 - loss: 0.953 - ETA: 2:20 - loss: 0.953 - ETA: 2:18 - loss: 0.953 - ETA: 2:15 - loss: 0.954 - ETA: 2:13 - loss: 0.953 - ETA: 2:10 - loss: 0.953 - ETA: 2:08 - loss: 0.954 - ETA: 2:06 - loss: 0.954 - ETA: 2:03 - loss: 0.955 - ETA: 2:01 - loss: 0.955 - ETA: 1:59 - loss: 0.955 - ETA: 1:57 - loss: 0.956 - ETA: 1:54 - loss: 0.957 - ETA: 1:52 - loss: 0.958 - ETA: 1:50 - loss: 0.957 - ETA: 1:48 - loss: 0.957 - ETA: 1:45 - loss: 0.956 - ETA: 1:43 - loss: 0.957 - ETA: 1:41 - loss: 0.957 - ETA: 1:39 - loss: 0.957 - ETA: 1:37 - loss: 0.957 - ETA: 1:34 - loss: 0.956 - ETA: 1:32 - loss: 0.958 - ETA: 1:30 - loss: 0.957 - ETA: 1:28 - loss: 0.958 - ETA: 1:26 - loss: 0.957 - ETA: 1:24 - loss: 0.957 - ETA: 1:21 - loss: 0.957 - ETA: 1:19 - loss: 0.957 - ETA: 1:17 - loss: 0.957 - ETA: 1:15 - loss: 0.957 - ETA: 1:13 - loss: 0.957 - ETA: 1:11 - loss: 0.958 - ETA: 1:09 - loss: 0.959 - ETA: 1:07 - loss: 0.959 - ETA: 1:04 - loss: 0.959 - ETA: 1:02 - loss: 0.958 - ETA: 1:00 - loss: 0.958 - ETA: 58s - loss: 0.958 - ETA: 56s - loss: 0.95 - ETA: 54s - loss: 0.95 - ETA: 52s - loss: 0.95 - ETA: 50s - loss: 0.95 - ETA: 48s - loss: 0.95 - ETA: 46s - loss: 0.95 - ETA: 44s - loss: 0.95 - ETA: 42s - loss: 0.95 - ETA: 40s - loss: 0.95 - ETA: 38s - loss: 0.95 - ETA: 36s - loss: 0.95 - ETA: 34s - loss: 0.95 - ETA: 31s - loss: 0.95 - ETA: 29s - loss: 0.95 - ETA: 27s - loss: 0.95 - ETA: 25s - loss: 0.95 - ETA: 23s - loss: 0.95 - ETA: 21s - loss: 0.95 - ETA: 19s - loss: 0.96 - ETA: 17s - loss: 0.95 - ETA: 15s - loss: 0.95 - ETA: 13s - loss: 0.95 - ETA: 11s - loss: 0.95 - ETA: 9s - loss: 0.9596 - ETA: 7s - loss: 0.959 - ETA: 5s - loss: 0.959 - ETA: 3s - loss: 0.960 - ETA: 1s - loss: 0.960 - 371s 2s/step - loss: 0.9599 - val_loss: 1.3800\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.27371\n"
     ]
    }
   ],
   "source": [
    "tf_configuration = tf.ConfigProto()\n",
    "tf_configuration.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=tf_configuration))\n",
    "start = time.time()\n",
    "callbacks = decoder_model.fit_generator(generator=generator,\n",
    "                                        steps_per_epoch=int(len(train_filenames_with_all_captions) / config.DECODER.BATCH_SIZE),\n",
    "                                        epochs=config.DECODER.EPOCHS,\n",
    "                                        callbacks=[checkpoints, reduce_lr],\n",
    "                                        validation_data=val_generator,\n",
    "                                        validation_steps=config.DECODER.VAL_STEPS)\n",
    "time_train = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for training: 6747.911556720734 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Time for training: {} seconds\".format(time_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(config.PATH.CALLBACKS_PATH):\n",
    "    os.mkdir(config.PATH.CALLBACKS_PATH)   \n",
    "callback_df = pd.DataFrame(callbacks.history)\n",
    "callback_df.to_csv(callbacks_path, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
